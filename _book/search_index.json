[["index.html", "Post-Fire Conifer Regeneration Part 1 About", " Post-Fire Conifer Regeneration Casey Menick 2022-12-05 Part 1 About Code in progress! The project seeks to analyze the trajectory and patterning of conifer regeneration following high-severity wildfire "],["fire-selection.html", "Part 2 Fire Selection 2.1 Set Up 2.2 Define Fire Parameters 2.3 Final Fire Dataset 2.4 Mapping 2.5 Export Data", " Part 2 Fire Selection 2.1 Set Up 2.1.1 Libraries library(tidyverse) library(terra) library(sf) library(mapview) library(raster) library(rgeos) library(lubridate) library(ggplot2) library(exactextractr) library(patchwoRk) library(gridExtra) library(knitr) library(rasterVis) library(RColorBrewer) 2.1.2 USDA National Forest Type Group Dataset Conifer Forest Type Groups: Douglas-Fir, Fir-Spruce-Mountain Hemlock, Lodgepole Pine # forest type groups and key conus_forestgroup &lt;- raster(&#39;data/forest_type/conus_forestgroup.tif&#39;) forest_codes &lt;- read_csv(&#39;data/forest_type/forestgroupcodes.csv&#39;) # set crs crs = crs(conus_forestgroup) 2.1.3 EPA level-3 Ecoregions Canadian Rockies, Idaho Batholith, Middle Rockies, Columbian Mountains - Northern Rockies # level 3 ecoregions l3eco &lt;- st_read(&#39;data/ecoregion/us_eco_l3.shp&#39;) %&gt;% st_transform(., crs=crs) # select northern rocky mountains from level3 ecoregions eco_select &lt;- l3eco %&gt;% filter(NA_L3NAME %in% c(&#39;Canadian Rockies&#39;,&#39;Columbia Mountains/Northern Rockies&#39;,&#39;Middle Rockies&#39;,&#39;Idaho Batholith&#39;)) 2.1.4 Mapping 2.1.4.1 Ecoregions # mapview palette &lt;- brewer.pal(18,&quot;YlGn&quot;) palette[1] &lt;- rgb(255, 255, 255, maxColorValue=255, alpha=1) mapview(eco_select,na.color=palette[1],legend=TRUE) 2.1.4.2 Forest Type Groups # convert raster values to factors forestgroup_eco &lt;- crop(conus_forestgroup,eco_select) %&gt;% mask(.,eco_select) %&gt;% as.factor() # add a labels for forest type code group_levels &lt;- levels(forestgroup_eco)[[1]] group_levels[[&quot;forest_type&quot;]] &lt;- c(&quot;0: Unforested&quot;,&quot;120: Spruce/Fir&quot;,&quot;180: Pinyon/Juniper&quot;,&quot;200: Douglas-fir&quot;,&quot;220: Ponderosa Pine&quot;,&quot;240: Western White Pine&quot;,&quot;260: Fir/Spruce/Mountain Hemlock&quot;,&quot;280: Lodgepole Pine&quot;,&quot;300: Hemlock/Sitka Spruce&quot;,&quot;320: Western Larch&quot;,&quot;360: Other Western Softwood&quot;,&quot;370: California Mixed Conifer&quot;,&quot;400: Oak/Pine&quot;,&quot;500: Oak/Hickory&quot;,&quot;700: Elm/Ash/Cottonwood&quot;,&quot;900: Aspen/Birch&quot;,&quot;920: Western Oak&quot;,&quot;950: Other Western Hardwoods&quot;) levels(forestgroup_eco) &lt;- group_levels # mapview mapview(forestgroup_eco, col.regions=palette,na.color=palette[1],legend=TRUE) 2.2 Define Fire Parameters 2.2.1 Monitoring Trends in Burn Severity (MTBS) Dataset Criteria: -1988-1991 -500+ acres of high-severity -Within selected ecoregions -&gt;25% of selected forest types # mtbs fire perimeters mtbs_full &lt;- st_read(&#39;data/mtbs/mtbs_perims_DD.shp&#39;) %&gt;% st_transform(., crs=crs) mtbs_select &lt;- mtbs_full %&gt;% mutate(state = str_sub(Event_ID,0,2), year = year(as.Date(Ig_Date))) %&gt;% filter(state %in% c(&quot;WA&quot;,&quot;ID&quot;,&quot;MT&quot;,&quot;WY&quot;,&quot;SD&quot;), between(Ig_Date, as.Date(&#39;1988-01-1&#39;), as.Date(&#39;1991-12-31&#39;))) 2.2.2 Group Adjacent Fires # function to group adjoining fire polygons to ensure contiguous high-severity patches group_fires &lt;- function(mtbs_year) { # join the polygons with themselves, and remove those that do not join with any besides themselves combined&lt;- st_join(mtbs_year, mtbs_year, join=st_is_within_distance, dist = 180, left = TRUE,remove_self = TRUE) %&gt;% drop_na(Event_ID.y)%&gt;% dplyr::select(Event_ID.x,Event_ID.y) if(nrow(combined)&gt;=1){ # if there are overlaps for this years fires... # partition data into that that has overlap, and that that does not overlap &lt;- mtbs_year %&gt;% filter(Event_ID %in% combined$Event_ID.x) no_overlap &lt;- mtbs_year %&gt;% filter(!(Event_ID %in% combined$Event_ID.x)) print(paste0(&quot;there are &quot;,nrow(overlap),&quot; overlapping polygons&quot;)) # join all overlapping features, and buffer to ensure proper grouping overlap_union &lt;- st_union(overlap) %&gt;% st_buffer(190) # break apart the joined polygons into their individual groups groups &lt;- st_as_sf(st_cast(overlap_union ,to=&#39;POLYGON&#39;,group_or_split=TRUE)) %&gt;% mutate(year = mean(mtbs_year$year), Fire_ID = str_c(&quot;Fire_&quot;,c(1:nrow(.)),&quot;_&quot;,year)) %&gt;% rename(geometry = x) print(paste0(&quot;polygons formed into &quot;,nrow(groups),&quot; groups&quot;)) # join back with original dataset to return to unbuffered geometry grouped_overlap &lt;- st_join(overlap,groups,left=TRUE) # arrange by the new grouping joined_overlap_groups &lt;- grouped_overlap %&gt;% group_by(Fire_ID) %&gt;% tally()%&gt;% st_buffer(1) %&gt;% dplyr::select(Fire_ID) %&gt;% mutate(year = mean(mtbs_year$year)) # add new ID to the freestanding polygons no_overlap_groups &lt;- no_overlap %&gt;% mutate(Fire_ID = str_c(&quot;Fire_&quot;,nrow(groups)+c(1:nrow(no_overlap)),&quot;_&quot;,year)) %&gt;% dplyr::select(Fire_ID,year) # join the new grouped overlap and the polygons without overlap fires_export &lt;- rbind(joined_overlap_groups,no_overlap_groups) return(fires_export) } else { # if there are no overlaps for this year... print(&quot;no overlapping polygons&quot;) fires_export &lt;- mtbs_year %&gt;% mutate(Fire_ID = str_c(&quot;Fire_&quot;,c(1:nrow(.)),&quot;_&quot;,year)) %&gt;% dplyr::select(Fire_ID,year) return(fires_export) } } # group adjacent polygons within each fire year fires_88 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1988)) ## [1] &quot;there are 22 overlapping polygons&quot; ## [1] &quot;polygons formed into 7 groups&quot; fires_89 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1989)) ## [1] &quot;there are 2 overlapping polygons&quot; ## [1] &quot;polygons formed into 1 groups&quot; fires_90 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1990)) ## [1] &quot;there are 2 overlapping polygons&quot; ## [1] &quot;polygons formed into 1 groups&quot; fires_91 &lt;- group_fires(mtbs_select %&gt;% filter(year == 1991)) ## [1] &quot;no overlapping polygons&quot; # join each fire year, filter by area mtbs_grouped &lt;- rbind(fires_88,fires_89,fires_90,fires_91)%&gt;% mutate(area_ha = as.numeric(st_area(geometry))/10000, area_acres = area_ha*2.471) 2.2.3 Select Fires by Ecoregion and Forest Type # assign ecoregion and proportions of forest type to each fire polygon fires_join &lt;- st_join(mtbs_grouped,eco_select,join=st_intersects,left=FALSE,largest=TRUE) %&gt;% left_join(., exact_extract(conus_forestgroup,mtbs_grouped, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = function(value, coverage_fraction) { data.frame(value = value, frac = coverage_fraction / sum(coverage_fraction)) %&gt;% group_by(value) %&gt;% summarize(freq = sum(frac), .groups = &#39;drop&#39;) %&gt;% pivot_wider(names_from = &#39;value&#39;, names_prefix = &#39;freq_&#39;, values_from = &#39;freq&#39;)}) %&gt;% mutate(across(starts_with(&#39;freq&#39;), replace_na, 0))) # remove unnecessary columns, cleanup names # filter to ensure fire polygons are at least 25% type of interest fires &lt;- fires_join %&gt;% dplyr::select(&quot;Fire_ID&quot;,&quot;year&quot;,&quot;area_ha&quot;,&quot;area_acres&quot;,&quot;US_L3NAME&quot;,&quot;freq_0&quot;,&quot;freq_200&quot;,&quot;freq_220&quot;,&quot;freq_260&quot;,&quot;freq_280&quot;) %&gt;% rename(&quot;ecoregion&quot; = &quot;US_L3NAME&quot;, &quot;freq_df&quot;=&quot;freq_200&quot;, &quot;freq_pp&quot;=&quot;freq_220&quot;, &quot;freq_fs&quot;=&quot;freq_260&quot;, &quot;freq_lpp&quot;=&quot;freq_280&quot;) %&gt;% mutate(freq_allother = 1-(freq_0 + freq_df+freq_pp+freq_fs+freq_lpp), freq_forested = 1- freq_0, freq_ideal = freq_df+freq_fs+freq_lpp)%&gt;% mutate(across(starts_with(&#39;freq&#39;), round,2))%&gt;% filter(freq_ideal &gt; 0.25) 2.2.4 Select Fires by Burn Severity # import all mtbs rasters via a list rastlist &lt;- list.files(path = &quot;data/mtbs&quot;, pattern=&#39;.tif&#39;, all.files=TRUE, full.names=TRUE) allrasters &lt;- lapply(rastlist, raster) names(allrasters) &lt;- str_c(&quot;y&quot;, str_sub(rastlist,22,25)) # create empty dataframe severity_list &lt;- list() # loop through mtbs mosasics for 1988-1991 # extract mtbs burn severity raster for all selected fires # calculate burn severity percentages for each fire for (i in names(allrasters)){ mtbs_year &lt;- allrasters[[i]] fire_year &lt;- filter(fires, year==str_sub(i,2,5)) raster_extract &lt;- exact_extract(mtbs_year,fire_year, max_cells_in_memory = 3e+09,coverage_area=TRUE) names(raster_extract) &lt;- fire_year$Fire_ID output_select &lt;- bind_rows(raster_extract, .id = &quot;Fire_ID&quot;)%&gt;% group_by(Fire_ID , value) %&gt;% summarize(total_area = sum(coverage_area)) %&gt;% group_by(Fire_ID) %&gt;% mutate(proportion = total_area/sum(total_area))%&gt;% dplyr::select(&quot;Fire_ID&quot;,&quot;value&quot;,&quot;proportion&quot;) %&gt;% spread(.,key=&quot;value&quot;,value = &quot;proportion&quot;) severity_list[[i]] &lt;- output_select } # combine extracted raster datasets severity_df &lt;- do.call(rbind, severity_list) # join burn severity % to fires polygons # fix naming # filter dataset for 500 acres high severity fires_severity &lt;- left_join(fires,severity_df,by=&quot;Fire_ID&quot;)%&gt;% rename(noburn= &quot;1&quot;,lowsev = &quot;2&quot;, medsev = &quot;3&quot;, highsev = &quot;4&quot;,regrowth = &quot;5&quot;, error = &quot;6&quot;) %&gt;% dplyr::select(- &quot;NaN&quot;,-&quot;regrowth&quot;,-&quot;error&quot;) %&gt;% mutate(highsev_acres = area_acres*highsev)%&gt;% filter(highsev_acres &gt; 500) 2.2.5 Clean Up Dataset # get the most common forest type within each polygon fires_select &lt;- fires_severity %&gt;% left_join(.,exact_extract(conus_forestgroup,fires_severity, &#39;mode&#39;, append_cols = TRUE, max_cells_in_memory = 3e+08)) fires_select$mode &lt;- as.factor(fires_select$mode) fires_select &lt;- fires_select %&gt;% mutate(fire_foresttype = case_when(mode==200 ~ &quot;Douglas-Fir&quot;, mode==220 ~ &quot;Ponderosa&quot;, mode==260 ~ &quot;Fir-Spruce&quot;, mode==280 ~ &quot;Lodegepole Pine&quot;, TRUE ~ &quot;Other&quot;), Fire_ID = str_c(&quot;Fire_&quot;,c(1:nrow(.)),&quot;_&quot;,year)) # join the grouped fires back to original mtbs boundaries fires_mtbs &lt;- st_join(mtbs_select,fires_select,left=FALSE,largest=TRUE) %&gt;% filter(year.x==year.y)%&gt;% dplyr::select(&quot;Event_ID&quot;,&quot;Incid_Name&quot;,&quot;Fire_ID&quot;,&quot;Ig_Date&quot;,&quot;year.y&quot;,&quot;state&quot;,&quot;BurnBndAc&quot;,&quot;ecoregion&quot;) %&gt;% rename(year= year.y) 2.3 Final Fire Dataset 2.3.1 Dataset Overview full_dataset &lt;- fires_select %&gt;% st_drop_geometry() %&gt;% dplyr::select(Fire_ID,year,ecoregion,fire_foresttype,area_acres,highsev) %&gt;% mutate(highsev = round(highsev,2), area_acres = round(area_acres,0)) kable(full_dataset, align = &#39;c&#39;, padding = 1, col.names = c(&quot;Fire ID&quot;, &quot;Year&quot;, &quot;Ecoregion&quot;, &quot;Majority Forest Type&quot;,&quot;Area (acres)&quot;, &quot;High Severity %&quot;), caption = &quot;High-Severity Conifer-Dominated Fires 1988-1991&quot;) Table 2.1: High-Severity Conifer-Dominated Fires 1988-1991 Fire ID Year Ecoregion Majority Forest Type Area (acres) High Severity % Fire_1_1988 1988 Middle Rockies Fir-Spruce 342005 0.27 Fire_2_1988 1988 Middle Rockies Lodegepole Pine 777690 0.28 Fire_3_1988 1988 Middle Rockies Lodegepole Pine 448911 0.21 Fire_4_1988 1988 Idaho Batholith Douglas-Fir 5651 0.16 Fire_5_1988 1988 Idaho Batholith Fir-Spruce 11945 0.23 Fire_6_1988 1988 Idaho Batholith Douglas-Fir 50666 0.07 Fire_7_1988 1988 Middle Rockies Lodegepole Pine 167870 0.50 Fire_8_1988 1988 Idaho Batholith Douglas-Fir 25889 0.02 Fire_9_1988 1988 Idaho Batholith Douglas-Fir 8312 0.17 Fire_10_1988 1988 Canadian Rockies Lodegepole Pine 42492 0.52 Fire_11_1988 1988 Idaho Batholith Fir-Spruce 45075 0.43 Fire_12_1988 1988 Middle Rockies Lodegepole Pine 5633 0.24 Fire_13_1988 1988 Idaho Batholith Douglas-Fir 4962 0.25 Fire_14_1988 1988 Middle Rockies Other 35864 0.46 Fire_15_1988 1988 Idaho Batholith Fir-Spruce 19499 0.29 Fire_16_1988 1988 Idaho Batholith Fir-Spruce 5626 0.09 Fire_17_1988 1988 Idaho Batholith Fir-Spruce 12746 0.40 Fire_18_1988 1988 Middle Rockies Other 13108 0.48 Fire_19_1988 1988 Idaho Batholith Fir-Spruce 7241 0.27 Fire_20_1988 1988 Idaho Batholith Fir-Spruce 6559 0.13 Fire_21_1988 1988 Middle Rockies Fir-Spruce 3113 0.17 Fire_22_1988 1988 Middle Rockies Other 29233 0.16 Fire_23_1988 1988 Middle Rockies Other 1363 0.41 Fire_24_1988 1988 Idaho Batholith Douglas-Fir 48136 0.31 Fire_25_1988 1988 Northern Rockies Douglas-Fir 8089 0.25 Fire_26_1988 1988 Middle Rockies Douglas-Fir 8588 0.56 Fire_27_1988 1988 Northern Rockies Douglas-Fir 11403 0.30 Fire_28_1988 1988 Northern Rockies Douglas-Fir 21854 0.25 Fire_29_1988 1988 Canadian Rockies Douglas-Fir 33844 0.27 Fire_30_1988 1988 Northern Rockies Douglas-Fir 1909 0.31 Fire_31_1988 1988 Middle Rockies Other 6282 0.47 Fire_32_1989 1989 Idaho Batholith Fir-Spruce 13334 0.15 Fire_33_1989 1989 Middle Rockies Lodegepole Pine 3298 0.37 Fire_34_1989 1989 Idaho Batholith Douglas-Fir 4928 0.38 Fire_35_1989 1989 Idaho Batholith Douglas-Fir 47680 0.02 Fire_36_1989 1989 Idaho Batholith Fir-Spruce 2486 0.30 Fire_37_1989 1989 Idaho Batholith Fir-Spruce 5566 0.30 Fire_38_1989 1989 Idaho Batholith Fir-Spruce 7443 0.28 Fire_39_1989 1989 Idaho Batholith Fir-Spruce 6786 0.26 Fire_40_1989 1989 Idaho Batholith Douglas-Fir 8733 0.12 Fire_41_1989 1989 Idaho Batholith Fir-Spruce 1615 0.49 Fire_42_1989 1989 Idaho Batholith Lodegepole Pine 2488 0.33 Fire_43_1989 1989 Idaho Batholith Fir-Spruce 3081 0.27 Fire_44_1990 1990 Middle Rockies Douglas-Fir 2535 0.45 Fire_45_1990 1990 Idaho Batholith Fir-Spruce 3418 0.53 Fire_46_1990 1990 Idaho Batholith Douglas-Fir 2249 0.49 Fire_47_1990 1990 Middle Rockies Lodegepole Pine 2763 0.41 Fire_48_1990 1990 Middle Rockies Other 13461 0.19 Fire_49_1991 1991 Middle Rockies Douglas-Fir 6978 0.31 Fire_50_1991 1991 Middle Rockies Douglas-Fir 3097 0.18 Fire_51_1991 1991 Middle Rockies Fir-Spruce 6995 0.14 Fire_52_1991 1991 Idaho Batholith Douglas-Fir 1186 0.55 Fire_53_1991 1991 Northern Rockies Fir-Spruce 7095 0.39 Fire_54_1991 1991 Northern Rockies Fir-Spruce 2478 0.51 2.4 Mapping 2.4.1 Selected fires by year # plot mapview(fires_select, zcol = &quot;year&quot;) 2.4.2 Selected fires by majority forest type # plot mapview(fires_select, zcol = &quot;fire_foresttype&quot;) 2.5 Export Data 2.5.1 Final Cleanup for Export # reformat and project fires_export &lt;- fires_select %&gt;% mutate(year = as.integer(year)) %&gt;% st_transform(., crs=&quot;EPSG:4326&quot;) mtbs_export &lt;- fires_mtbs %&gt;% mutate(year = as.integer(year)) %&gt;% st_transform(., crs=&quot;EPSG:4326&quot;) 2.5.2 Export # st_write(fires_export, &quot;data/fire_boundaries/&quot;, &quot;fires_export.shp&quot;, driver = &#39;ESRI Shapefile&#39;) # st_write(mtbs_export, &quot;data/fire_boundaries/&quot;, &quot;mbts_export.shp&quot;, driver = &#39;ESRI Shapefile&#39;) "],["calculation-of-high-severity.html", "Part 3 Calculation of High-Severity 3.1 Set Up 3.2 Imagery 3.3 Burn Indices 3.4 Export", " Part 3 Calculation of High-Severity 3.1 Set Up 3.1.1 Import Fire Boundaries var mtbs_all = ee.FeatureCollection(&quot;USFS/GTAC/MTBS/burned_area_boundaries/v1&quot;); var fires = ee.FeatureCollection(&quot;projects/westernconiferregen/assets/fires_export&quot;); 3.1.2 Clean Fire Boundaries // filter mtbs fire perimeters to relevant date range var mtbs = mtbs_all .filter(ee.Filter.gt(&quot;Ig_Date&quot;,ee.Date(&#39;1984-01-01&#39;).millis())) .filter(ee.Filter.lt(&quot;Ig_Date&quot;,ee.Date(&#39;1992-12-31&#39;).millis())); // list fire IDs and get total number of fires var fireID = ee.List(fires.aggregate_array(&#39;Fire_ID&#39;)).getInfo(); var nFires = fireID.length; 3.2 Imagery 3.2.1 Import Landsat 5 // Landsat 5 Surface Reflectance Tier 1 collection var ls5_SR = ee.ImageCollection(&#39;LANDSAT/LT05/C01/T1_SR&#39;); 3.2.2 Prepare Landsat Data // function to get NBR, qa pixel bands var ls5_getbands = function(lsImage){ var nbr = lsImage.normalizedDifference([&#39;B4&#39;, &#39;B7&#39;]).toFloat(); var qa = lsImage.select([&#39;pixel_qa&#39;]); return nbr.addBands([qa]) .select([0,1], [&#39;nbr&#39;, &#39;pixel_qa&#39;]) .copyProperties(lsImage, [&#39;system:time_start&#39;]); }; // function to get clear pixels var ls5_qa = function(lsImg){ var quality =lsImg.select([&#39;pixel_qa&#39;]); var clear = quality.bitwiseAnd(8).eq(0) // cloud shadow .and(quality.bitwiseAnd(32).eq(0) // cloud .and(quality.bitwiseAnd(4).eq(0) // water .and(quality.bitwiseAnd(16).eq(0)))); // snow return lsImg.updateMask(clear).select([0]) .copyProperties(lsImg, [&#39;system:time_start&#39;]); }; // function to project to EPSG 4326 var ls5_project = function(lsImage){ var proj4326 = ee.Projection(&#39;EPSG:4326&#39;).atScale(30); var lsImage_proj = lsImage.reproject(proj4326); return lsImage_proj; }; // Map functions across Landsat Collection var ls5 = ls5_SR.map(ls5_getbands) .map(ls5_qa) .map(ls5_project); 3.3 Burn Indices 3.3.1 Calculate RdNBR // Calculate burn severity metrics for each fire var indices = ee.ImageCollection(fires.map(function(fire){ // get fire bounds var fireBounds = fire.geometry().bounds(); // get pre- and post-fire years var fireYear = ee.Date.parse(&#39;YYYY&#39;, fire.get(&#39;year&#39;)); var preFireYear = fireYear.advance(-1, &#39;year&#39;); var postFireYear = fireYear.advance(1, &#39;year&#39;); // filter ls5 to fire bounds and dates to get pre and post-fire imagery var preNBR = ls5.filterBounds(fireBounds) .filterDate(preFireYear, fireYear) .filter(ee.Filter.dayOfYear(152, 273)) .mean() .rename(&#39;preNBR&#39;); var postNBR = ls5.filterBounds(fireBounds) .filterDate(postFireYear, fireYear.advance(2, &#39;year&#39;)) .filter(ee.Filter.dayOfYear(152, 273)) .mean() .rename(&#39;postNBR&#39;); // calculate sqrt of pre-fire NBR to relativize var preNBRsq = preNBR .expression(&quot;abs(b(&#39;preNBR&#39;)) &lt; 0.001 ? 0.001&quot; + &quot;: b(&#39;preNBR&#39;)&quot;) .abs().sqrt().rename(&#39;preNBRsq&#39;).toFloat(); // combine pre and post-fire imagery var fireIndices = preNBR.addBands(postNBR).addBands(preNBRsq); // calculate dNBR var dnbr = fireIndices.expression(&quot;(b(&#39;preNBR&#39;) - b(&#39;postNBR&#39;)) * 1000&quot;).rename(&#39;dnbr&#39;).toFloat(); // calculate offset value from 180-m buffer of unburned area outside the fire perimeter var ring = fire.buffer(180).difference(mtbs.geometry()); var offset = ee.Image.constant(ee.Number(dnbr.select(&#39;dnbr&#39;).reduceRegion({ reducer: ee.Reducer.mean(), geometry: ring.geometry(), scale: 30, maxPixels: 1e9 }).get(&#39;dnbr&#39;))).rename(&#39;offset&#39;).toFloat().addBands(dnbr); // calculate dNBR with offset var dnbr_w_offset = fireIndices .addBands(offset.expression(&quot;b(&#39;dnbr&#39;) - b(&#39;offset&#39;)&quot;).rename(&#39;dnbr_w_offset&#39;).toFloat()); // calculate RdNBR with offset var rdnbr_w_offset = dnbr_w_offset.expression(&quot;b(&#39;dnbr_w_offset&#39;) / b(&#39;preNBRsq&#39;)&quot;).rename(&#39;rdnbr_w_offset&#39;).toFloat(); return rdnbr_w_offset.select(&#39;rdnbr_w_offset&#39;).set({&#39;fireID&#39;: fire.get(&#39;Fire_ID&#39;),&#39;fireYear&#39;: fire.get(&#39;year&#39;) }); })); 3.4 Export 3.4.1 Export Each Fire RdNBR to Drive // export to drive for (var j = 0; j &lt; nFires; j++){ var id = fireID[j]; var Name = id; var fireExport = ee.Image(indices.filterMetadata(&#39;fireID&#39;, &#39;equals&#39;, id).first()); var fireBounds = ee.Feature(fires.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id).first()).geometry().bounds(); var firePolygon = ee.Feature(fires.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id).first()).geometry(); var exportImg = fireExport.select(&#39;rdnbr_w_offset&#39;).toInt().clip(firePolygon); Export.image.toDrive({ image: exportImg, folder: &quot;fire_rdnbr_rasters&quot;, description: Name, crs: &quot;EPSG:4326&quot;, maxPixels: 1e13, scale: 30, region: fireBounds }); } "],["patch-formation.html", "Part 4 Patch Formation 4.1 Set Up 4.2 Create High-Severity Patches 4.3 Refine Patches 4.4 Mapping 4.5 Export Data", " Part 4 Patch Formation 4.1 Set Up 4.1.1 Libraries library(tidyverse) library(terra) library(patchwoRk) library(sf) library(mapview) library(exactextractr) library(lubridate) 4.1.2 Import RdNBR Rasters # import calculated RdNBR rasters for each fire boundary polygon rast_list &lt;- list.files(path = &quot;data/rdnbr_rasters&quot;, pattern=&#39;.tif&#39;, all.files=TRUE, full.names=TRUE) rast_all &lt;- lapply(rast_list, rast) rast_collection &lt;- sprc(rast_all) crs &lt;- crs(rast_collection[1]) 4.1.3 Import Fire Boundaries # import fire boundaries mtbs_export &lt;- st_read(&#39;data/fire_boundaries/mtbs_export.shp&#39;) %&gt;% st_transform(., crs=crs) fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(., crs=crs) # import forest type group raster conus_forestgroup &lt;- raster(&#39;data/forest_type/conus_forestgroup.tif&#39;) forest_codes &lt;- read_csv(&#39;data/forest_type/forestgroupcodes.csv&#39;) 4.2 Create High-Severity Patches 4.2.1 PatchMorph # loop through RdNBR rasters, assign &gt;640 to high severity category # utilize patchmorph to act as 3x3 cell majority filter patch_df &lt;- list() for (i in 1:length(rast_all)){ # print(i) rast_fire &lt;- raster(rast_collection[i]) rast_fire[rast_fire &lt; 640] &lt;- 0 rast_fire[rast_fire &gt;= 640] &lt;- 1 patch &lt;- patchMorph(rast_fire, spurThresh = 3, gapThresh = 3) patch_poly &lt;- as.polygons(rast(patch)) %&gt;% st_as_sf() df_union_cast &lt;- patch_poly %&gt;% st_cast(., &quot;POLYGON&quot;) %&gt;% filter(layer == 1) patch_df[[i]] &lt;- df_union_cast} patch_poly_all &lt;- do.call(rbind,patch_df) 4.3 Refine Patches # filter small patches patches_full &lt;- patch_poly_all %&gt;% mutate(patch_area_ha = as.numeric(st_area(.))/10000) %&gt;% filter(patch_area_ha &gt; 2.25) # join patches back to grouped fires patches_joined &lt;- st_join(patches_full,mtbs_export,join = st_intersects,left= FALSE,largest = TRUE) %&gt;% dplyr::select(-layer,-BurnBndAc) %&gt;% left_join(.,exact_extract(conus_forestgroup,., &#39;mode&#39;, append_cols = TRUE, max_cells_in_memory = 3e+08))%&gt;% mutate(patch_foresttype = case_when(mode==200 ~ &quot;Douglas-Fir&quot;, mode==220 ~ &quot;Ponderosa&quot;, mode==260 ~ &quot;Fir-Spruce&quot;, mode==280 ~ &quot;Lodegepole Pine&quot;, mode==0 ~ &quot;Unforested&quot;, TRUE ~ &quot;Other&quot;)) 4.4 Mapping mapview(patches_joined,col.regions = &quot;red&quot;) + mapview(fires_export, alpha.regions = 0, lwd = 2) 4.5 Export Data patches &lt;- patches_joined %&gt;% st_transform(crs = crs) # st_write(patches, &quot;data/patches/&quot;, &quot;highsev_patches.shp&quot;,driver = &#39;ESRI Shapefile&#39;) "],["sampling-quadrants.html", "Part 5 Sampling Quadrants 5.1 Set Up 5.2 Create Sampling Quadrants 5.3 Export Data", " Part 5 Sampling Quadrants 5.1 Set Up 5.1.1 Libraries library(elevatr) library(tidyverse) library(sf) library(terra) library(mapview) 5.1.2 Import High-Severity Patches and Fire Boundaries # data import patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% st_transform(crs=&quot;EPSG:4326&quot;) crs &lt;- crs(patches) patch_interiors&lt;- st_read(&quot;data/patches/highsev_patches_interior.shp&quot;) %&gt;% st_transform(crs=crs) patch_exteriors&lt;- st_read(&quot;data/patches/highsev_patches_exterior.shp&quot;) %&gt;% st_transform(crs=crs) mtbs_export &lt;- st_read(&#39;data/fire_boundaries/mtbs_export.shp&#39;) %&gt;% st_transform(crs=crs) fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(crs=crs) 5.2 Create Sampling Quadrants 5.2.1 Split Patches by North/South Aspects and Interior/Exterior # create list of fire IDs fire_list &lt;- unique(patches$Evnt_ID) quadrants_df = list() for(i in fire_list){ # filter patch interiors/exteriors to the selected fire patch_fire &lt;- patches %&gt;% filter(Evnt_ID == i) mapview(patch_fire) patches_interior &lt;- patch_interiors %&gt;% filter(Evnt_ID == i)%&gt;% st_make_valid() %&gt;% st_union() patches_exterior &lt;- patch_exteriors %&gt;% filter(Evnt_ID_1 == i)%&gt;% st_make_valid()%&gt;% st_union() # set event and fire id to the selected fire Evnt_ID &lt;- i Fire_ID &lt;-names(which.max(table(patch_fire$Fire_ID))) print(paste0(&quot;starting event &quot;,Evnt_ID,&quot; in fire group &quot;, Fire_ID)) # get and calculate cosine corrected aspect dem &lt;- get_elev_raster(patch_fire,z=11) aspect &lt;- terrain(dem, opt = &quot;aspect&quot;,unit = &quot;radians&quot;) ccaspect &lt;- cos(aspect) # positive aspects are north-facing, negative are south-facing ccaspect[ccaspect&gt;0] &lt;- 1 ccaspect[ccaspect&lt;0] &lt;- -1 ccaspect_poly &lt;- as.polygons(rast(ccaspect)) %&gt;% st_as_sf() pos_aspect &lt;- ccaspect_poly %&gt;% filter(layer==1)%&gt;% st_make_valid() neg_aspect &lt;- ccaspect_poly %&gt;% filter(layer==-1) %&gt;% st_make_valid() # get quadrants as the intersection of interior/exterior and pos/neg aspect pos_ext &lt;- st_intersection(patches_exterior,pos_aspect)%&gt;% st_make_valid() %&gt;% st_union() %&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;pos_ext&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) pos_int &lt;- st_intersection(patches_interior,pos_aspect)%&gt;% st_make_valid() %&gt;% st_union()%&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;pos_int&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) neg_ext &lt;- st_intersection(patches_exterior,neg_aspect)%&gt;% st_make_valid() %&gt;% st_union() %&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;neg_ext&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) neg_int &lt;- st_intersection(patches_interior, neg_aspect)%&gt;% st_make_valid() %&gt;% st_union() %&gt;% st_as_sf()%&gt;% mutate(quadrant = &quot;neg_int&quot;, Evnt_ID = i, quad_id_event = paste0(Evnt_ID,&quot;-&quot;,quadrant), Fire_ID = Fire_ID, quad_id_fire = paste0(Fire_ID,&quot;-&quot;,quadrant)) # combine, export quadrants all_quadrants &lt;- rbind(neg_int,pos_int,neg_ext,pos_ext) %&gt;% st_transform(crs=crs) quadrants_df[[i]] &lt;- all_quadrants print(paste0(&quot;completed&quot;)) } # bind list together quadrants_fullset &lt;- do.call(rbind,quadrants_df) %&gt;% st_as_sf() 5.2.2 Clean Quadrants # removes erroneous polygons created from irregular fire boundary shapes # removes small border mismatched fire quadrants_clean &lt;- quadrants_fullset %&gt;% mutate(area=as.numeric(st_area(x))) %&gt;% filter(area &gt; 1) %&gt;% group_by(Evnt_ID) %&gt;% mutate(n=n()) %&gt;% filter(n == 4) # clean up for export quadrants_export &lt;- quadrants_clean %&gt;% st_make_valid() %&gt;% st_as_sf() %&gt;% dplyr::select(-&quot;area&quot;)%&gt;% st_transform(crs=crs) 5.3 Export Data # st_write(quadrants_export,&quot;data/patches/&quot;,&quot;quadrants_export.shp&quot;,driver = &quot;ESRI Shapefile&quot;) "],["training-data.html", "Part 6 Training Data 6.1 Set Up 6.2 Import Data 6.3 Sampling Points 6.4 Export Data", " Part 6 Training Data 6.1 Set Up 6.1.0.1 Libraries library(tidyverse) library(sf) library(terra) 6.2 Import Data patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% st_transform(crs=&quot;EPSG: 4326&quot;) crs &lt;- crs(patches) quadrants &lt;- st_read(&quot;data/patches/quadrants_export.shp&quot;) %&gt;% st_transform(crs=crs) 6.3 Sampling Points 6.3.1 Import and Combine Training Points points_list &lt;- list.files(path = &quot;data/points/individual_fire_points/&quot;, pattern=&#39;.shp&#39;, all.files=TRUE, full.names=TRUE) points_all &lt;- lapply(points_list, st_read) points &lt;- do.call(rbind,points_all) %&gt;% st_transform(crs=crs) 6.3.2 Assign Points and Clean Data # join points dataset back to fires to fill out dataset points_joined &lt;- st_join(points,patches,left=TRUE,largest=TRUE) %&gt;% st_join(.,quadrants,left=TRUE,largest=TRUE) ## Warning: attribute variables are assumed to be spatially constant throughout all ## geometries ## Warning: attribute variables are assumed to be spatially constant throughout all ## geometries points_cleaned &lt;- points_joined %&gt;% dplyr::select(&quot;class&quot;,&quot;ptch_r_&quot;,&quot;Evnt_ID.x&quot;,&quot;Incd_Nm&quot;,&quot;Fire_ID.x&quot;,&quot;year&quot;,&quot;ecoregn&quot;,&quot;ptch_fr&quot;,&quot;quadrnt&quot;,&quot;qd_d_vn&quot;,&quot;qd_d_fr&quot;) %&gt;% rename(patch_area_ha = ptch_r_, Event_ID = Evnt_ID.x, Incid_Name = Incd_Nm, Fire_ID = Fire_ID.x, patch_frtype = ptch_fr, quad = quadrnt, quad_event_id= qd_d_vn, quad_fire_id=qd_d_fr) %&gt;% st_transform(crs=crs) 6.4 Export Data # st_write(points_cleaned, &quot;data/points/&quot;, &quot;points_export.shp&quot;,driver = &#39;ESRI Shapefile&#39;) "],["snow-cover-imagery.html", "Part 7 Snow Cover Imagery 7.1 Set Up 7.2 Create Snow-Cover Landsat Collection 7.3 Create Annual Image Composites 7.4 Prepare and Export Images", " Part 7 Snow Cover Imagery 7.1 Set Up 7.1.1 Import Fire Boundaries // import fire polygons var fires_export = ee.FeatureCollection(&quot;projects/westernconiferregen/assets/fires_export&quot;); var fires_export_buffer1500 = ee.FeatureCollection(&quot;projects/westernconiferregen/assets/fires_export_buffer1500&quot;); 7.1.2 Import Landsat Imagery // import Landsat 4,5,7, rename bands var ls7 = ee.ImageCollection(&#39;LANDSAT/LE07/C01/T1_SR&#39;), ls5 = ee.ImageCollection(&#39;LANDSAT/LT05/C01/T1_SR&#39;), ls4 = ee.ImageCollection(&#39;LANDSAT/LT04/C01/T1_SR&#39;); var ls4_7 = ee.ImageCollection(ls7.merge(ls5).merge(ls4)).map(function(image) { var bands = [&#39;B1&#39;,&#39;B2&#39;, &#39;B3&#39;, &#39;B4&#39;, &#39;B5&#39;, &#39;B7&#39;, &#39;pixel_qa&#39;]; var new_bands = [&#39;blue&#39;, &#39;green&#39;, &#39;red&#39;, &#39;nir&#39;, &#39;swir1&#39;, &#39;swir2&#39;, &#39;pixel_qa&#39;]; return image.select(bands).rename(new_bands); }); // import Landsat 8, rename bands var ls8 = ee.ImageCollection(&#39;LANDSAT/LC08/C01/T1_SR&#39;).map(function(image) { var bands = [&#39;B2&#39;, &#39;B3&#39;, &#39;B4&#39;, &#39;B5&#39;, &#39;B6&#39;, &#39;B7&#39;, &#39;pixel_qa&#39;]; var new_bands = [&#39;blue&#39;, &#39;green&#39;, &#39;red&#39;, &#39;nir&#39;, &#39;swir1&#39;, &#39;swir2&#39;, &#39;pixel_qa&#39;]; return image.select(bands).rename(new_bands); }); // merge Landsat 4-7 and 8 with renamed bands var ls4_8 = ee.ImageCollection(ls8.merge(ls4_7)); 7.2 Create Snow-Cover Landsat Collection 7.2.1 Functions to Prepare Images 7.2.1.1 Get Spectral Indices // function: get spectral indices var calc_indices = function(image) { return image .addBands(image.normalizedDifference([&#39;nir&#39;, &#39;red&#39;]).double().rename(&#39;ndvi&#39;)) .addBands(image.normalizedDifference([&#39;green&#39;, &#39;nir&#39;]).double().rename(&#39;ndwi&#39;)) .addBands(image.normalizedDifference([&#39;nir&#39;, &#39;swir2&#39;]).double().rename(&#39;nbr&#39;)) .addBands(image.normalizedDifference([&#39;swir1&#39;,&#39;swir2&#39;]).double().rename(&#39;nbr2&#39;)) .addBands(image.normalizedDifference([&#39;green&#39;, &#39;swir1&#39;]).double().rename(&#39;ndsi&#39;)) .addBands(image.normalizedDifference([&#39;nir&#39;,&#39;swir1&#39;]).double().rename(&#39;ndfsi&#39;)) .addBands(image.expression(&#39;2.5 * ((NIR - R) / (NIR + 6 * R - 7.5 * B + 1))&#39; ,{&#39;NIR&#39;:image.select(&#39;nir&#39;),&#39;R&#39;:image.select(&#39;red&#39;),&#39;B&#39;:image.select(&#39;blue&#39;)}).rename(&#39;evi&#39;))}; 7.2.1.2 Get Clear Images // function: pixel QA for clouds and bodies of water var qa_mask = function(lsImg){ var quality =lsImg.select([&#39;pixel_qa&#39;]); var clear = quality.bitwiseAnd(8).eq(0) // cloud shadow .and(quality.bitwiseAnd(32).eq(0) // cloud .and(quality.bitwiseAnd(4).eq(0))); // water return lsImg.updateMask(clear) .copyProperties(lsImg, [&#39;system:time_start&#39;]); }; 7.2.1.3 Get snow-Covered Pixels // function: mask pixels without snow based on NDSI and NDFSI var ndfsi_mask = function(image){ var ndfsi_snow = image.select(&#39;ndfsi&#39;).gt(0.4); return image.updateMask(ndfsi_snow); }; var ndsi_mask = function(image){ var ndsi_snow = image.select(&#39;ndsi&#39;).gt(0.4); return image.updateMask(ndsi_snow); }; 7.2.2 Map Functions Across Image Collection // map functions to create final Landsat collection var ls_indices = ls4_8.map(calc_indices) .map(qa_mask) .map(ndfsi_mask) .map(ndsi_mask); 7.3 Create Annual Image Composites 7.3.1 Functions to Create Annual Image Composites 7.3.1.1 Get Yearly Winter Image Composite // function: generates landsat composites for a given year&#39;s winter var get_composites = function(year) { // format years var year_start = ee.Number(year).format().slice(0,4); var year2 = ee.Number(year).add(1) var year_end = ee.Number(year2).format().slice(0,4); var month_start = &#39;-11-01&#39;; var month_end = &#39;-05-01&#39; var start_date = ee.String(year_start).cat(month_start) var end_date = ee.String(year_end).cat(month_end) // filter images by bounds, date range, bands; then take composite as median return ls_indices .filterBounds(fires_export_buffer1500) .filterDate(start_date,end_date) .filter(ee.Filter.calendarRange(12,4,&quot;month&quot;)) .select(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) .median() .set(&quot;year_start&quot;,year_start) .set(&quot;year_end&quot;,year_end) } 7.3.1.2 Get the Annual Imagery for Each Fire // function: clip each image from image collection by each feature in feature collection var clip_collections = function(imagecol, featcol){ // image collection loop var full_imagecol = imagecol.map(function(image){ // feature collection loop var full_featcol = featcol.map(function(feat){ // clip image and add feature property id return ee.Image(image).clip(ee.Feature(feat)) .set({&#39;feat&#39;: ee.Feature(feat).id()}) .set(&quot;Fire_ID&quot;,feat.get(&quot;Fire_ID&quot;)); }); // convert the FeatureCollection to list and convert it to ImageCollection return ee.ImageCollection.fromImages(full_featcol.toList(featcol.size())); }); // flatten, unnest lists return ee.ImageCollection(full_imagecol.flatten()); }; 7.3.2 Apply Functions to Each Image // list of start years var yearlist = ee.List.sequence(1984,2020,1); // map over the list of years to return landsat image composites for each var wrap_img = yearlist.map(get_composites); // clip landsat composites to each fire boundary var landsat_col = ee.ImageCollection.fromImages(wrap_img) // clip output var output = clip_collections(landsat_col, fires_export_buffer1500) 7.4 Prepare and Export Images // list fire IDs and get total number of fires var fireID = ee.List(fires_export_buffer1500.aggregate_array(&#39;Fire_ID&#39;)).getInfo(); var nFires = fireID.length; 7.4.1 Functions to Prepare Images 7.4.1.1 Get Year-Wavelength Band Names // rename bands to include imagery year var name_bands = function(image) { var div = ee.String(&#39;_&#39;); var year = image.getString(&#39;year_start&#39;); return image.rename(image.bandNames().map(function(bandName){ return ee.String(bandName).cat(div).cat(year); })); }; 7.4.1.2 Get Cleaned Band Name Strings // remove prefix from toBands function var clean_band_names = function(bandName){ return ee.String(bandName).slice(24,50) } 7.4.2 Export // loop through all fires, and create single image with bands from each landsat composite year // export to drive for (var j = 0; j &lt; nFires; j++){ var id = fireID[j]; var fireExport = output.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id) var firePolygon = ee.Feature(fires_export_buffer1500.filterMetadata(&#39;Fire_ID&#39;, &#39;equals&#39;, id).first()).geometry(); var fireExport_bands = fireExport.map(name_bands) var merge = fireExport_bands.toBands() var exportImg= merge.rename(merge.bandNames().map(clean_band_names)); Export.image.toDrive({ image: exportImg, folder: &quot;landsat_clipped_13bandyearly&quot;, description: id, crs: &quot;EPSG:4326&quot;, maxPixels: 1e13, scale: 30, region: firePolygon }); } "],["model-development.html", "Part 8 Model Development 8.1 Set Up 8.2 Prepare Training Data 8.3 Examine Data 8.4 Model 8.5 Random Forest", " Part 8 Model Development 8.1 Set Up 8.1.1 Libraries library(mapview) library(sf) library(terra) library(tidyverse) library(ggplot2) library(car) library(forcats) library(randomForest) library(raster) 8.1.2 Import Snow-Cover Landsat for 2020-2021 Winter # bring in snow-on landsat imagery tiles, merge into collection rast_list &lt;- list.files(path = &quot;data/landsat/landsat_2021&quot;, pattern=&#39;.tif&#39;, all.files=TRUE, full.names=TRUE) rast_all &lt;- lapply(rast_list, rast) rast_collection &lt;- sprc(rast_all) crs &lt;- crs(rast_collection[1]) 8.1.3 Import Fire Boundaries fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(., crs=crs) ## Reading layer `fires_export&#39; from data source ## `G:\\Other computers\\My Laptop\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\fire_boundaries\\fires_export.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 54 features and 20 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -118.6259 ymin: 42.57259 xmax: -106.9485 ymax: 48.9346 ## Geodetic CRS: WGS 84 8.1.4 Import Training Points # bring in training points points &lt;- st_read(&quot;data/points/points_export.shp&quot;) %&gt;% st_transform(crs=crs) ## Reading layer `points_export&#39; from data source ## `G:\\Other computers\\My Laptop\\Documents\\Grad School\\Research\\ConiferRegeneration\\data\\points\\points_export.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 3300 features and 11 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -118.6075 ymin: 42.57725 xmax: -106.9652 ymax: 48.83974 ## Geodetic CRS: WGS 84 8.2 Prepare Training Data 8.2.1 Extract Landsat Values # extract landsat values to each training point extracted_df &lt;- list() for(i in 1:length(rast_all)){ extracted_points &lt;- st_as_sf(terra::extract(rast_collection[i], points,bind = TRUE)) extracted_df[[i]] &lt;- extracted_points } training_dataset &lt;- do.call(rbind,extracted_df) %&gt;% mutate(absence = as.factor(case_when(class == &quot;absence&quot; ~ &quot;absence&quot;, TRUE ~ &quot;presence&quot;)), class = case_when(class == &quot;presence20to40&quot; ~ &quot;20-60%&quot;, class == &quot;presence40to60&quot; ~ &quot;20-60%&quot;, class == &quot;presence10to20&quot; ~ &quot;10-20%&quot;, class == &quot;presence1to10&quot; ~ &quot;1-10%&quot;, class == &quot;presencetrace&quot; ~ &quot;&lt;1%&quot;, class == &quot;presence60plus&quot; ~ &quot;&gt;60%&quot;, TRUE ~ &quot;absence&quot;), class = fct_relevel(as.factor(class),c(&quot;absence&quot;,&quot;&lt;1%&quot;,&quot;1-10%&quot;,&quot;10-20%&quot;,&quot;20-60%&quot;,&quot;&gt;60%&quot;))) %&gt;% rename(f_type = ptch_fr, area_ha = ptch_r_) %&gt;% st_drop_geometry() %&gt;% dplyr::select(-pixel_qa,-qd_vnt_,-qd_fr_d) %&gt;% drop_na(ndvi) 8.2.2 Training Data by Forest Type pres_abs_type &lt;- training_dataset %&gt;% group_by(f_type,absence) %&gt;% summarize(n=n()) %&gt;% mutate(percent= 100*n/sum(n)) %&gt;% filter(absence==&quot;presence&quot;) ## `summarise()` has grouped output by &#39;f_type&#39;. You can override using the ## `.groups` argument. pres_abs_type ## # A tibble: 7 × 4 ## # Groups: f_type [7] ## f_type absence n percent ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Douglas-Fir presence 414 75.8 ## 2 Fir-Spruce presence 510 68.1 ## 3 Lodegepole Pine presence 1023 85.3 ## 4 Other presence 16 66.7 ## 5 Ponderosa presence 11 100 ## 6 Unforested presence 396 70.8 ## 7 &lt;NA&gt; presence 1 50 8.3 Examine Data 8.3.1 Plot NDVI by Density Class ggplot(training_dataset,aes(class,ndvi)) + geom_boxplot() + labs(title = &quot;NDVI by Percent Conifer Cover Class: All Classes&quot;,x = &quot;Visually Estimated Conifer Percent Cover&quot;,y = &quot;NDVI&quot;) ggplot(training_dataset %&gt;% filter(class %in% c(&quot;absence&quot;,&quot;&lt;1%&quot;)),aes(class,ndvi)) + geom_boxplot()+ ylim(-.1,.1) + labs(title = &quot;NDVI by Percent Conifer Cover Class: Trace Conifer Class vs. Absence&quot;,x = &quot;Visually Estimated Conifer Percent Cover&quot;,y = &quot;NDVI&quot;) ggplot(training_dataset,aes(absence,ndvi)) + geom_boxplot() + labs(title = &quot;NDVI by Percent Conifer Cover Class: Presence vs. Absence &quot;,x = &quot;Visually Estimated Conifer Percent Cover&quot;,y = &quot;NDVI&quot;) 8.4 Model 8.4.1 Logistic # full model lm_conifer &lt;- glm(absence ~ red + green + blue + nir + swir1 + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset, family = binomial(logit)) vif(lm_conifer) ## red green blue nir swir1 swir2 ndsi ndfsi ## 24.774409 18.529373 12.977073 12.276477 19.984143 17.953243 11.134529 13.744253 ## ndvi evi nbr nbr2 ndwi ## 4.099328 1.043081 8.597776 1.738429 4.990175 # remove red (highest vif) lm_conifer &lt;- glm(absence ~ green + blue + nir + swir1 + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset, family = binomial(logit)) vif(lm_conifer) ## green blue nir swir1 swir2 ndsi ndfsi ndvi ## 14.356554 8.244362 12.244539 20.068658 17.904596 11.103446 13.759906 3.359440 ## evi nbr nbr2 ndwi ## 1.042982 8.573187 1.725957 4.719156 # remove swir1 (highest vif) lm_conifer &lt;- glm(absence ~ green + blue + nir + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset, family = binomial(logit)) vif(lm_conifer) ## green blue nir swir2 ndsi ndfsi ndvi evi ## 14.337537 8.229288 11.217559 6.247868 11.070839 12.541021 3.333257 1.042393 ## nbr nbr2 ndwi ## 8.145455 1.659048 4.699709 # remove green (highest vif) lm_conifer &lt;- glm(absence ~ blue + nir + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset, family = binomial(logit)) vif(lm_conifer) ## blue nir swir2 ndsi ndfsi ndvi evi nbr ## 4.050302 8.146971 6.197560 10.988332 12.483625 3.064783 1.041320 8.135376 ## nbr2 ndwi ## 1.654716 4.292147 # remove ndfsi (highest vif) lm_conifer &lt;- glm(absence ~ blue + nir + swir2 + ndsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset, family = binomial(logit)) vif(lm_conifer) ## blue nir swir2 ndsi ndvi evi nbr nbr2 ## 4.052957 8.121382 6.113613 6.695245 3.121780 1.040090 5.349073 1.409223 ## ndwi ## 4.160001 # remove nir (highest vif) lm_conifer &lt;- glm(absence ~ blue + swir2 + ndsi + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset, family = binomial(logit)) vif(lm_conifer) ## blue swir2 ndsi ndvi evi nbr nbr2 ndwi ## 2.983042 2.874443 6.562887 3.275605 1.037147 4.706273 1.412853 4.186073 # remove ndsi (highest vif) lm_conifer &lt;- glm(absence ~ blue + swir2 + ndvi + evi + nbr + nbr2 + ndwi, data = training_dataset, family = binomial(logit)) vif(lm_conifer) ## blue swir2 ndvi evi nbr nbr2 ndwi ## 2.941949 2.908175 3.293356 1.028575 1.789812 1.127839 3.411818 # all vif now below 5 # final model summary(lm_conifer) ## ## Call: ## glm(formula = absence ~ blue + swir2 + ndvi + evi + nbr + nbr2 + ## ndwi, family = binomial(logit), data = training_dataset) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.9597 0.0014 0.0471 0.4874 4.2004 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -5.603e+00 1.116e+00 -5.022 5.11e-07 *** ## blue 6.969e-05 2.556e-05 2.727 0.00639 ** ## swir2 -1.824e-03 2.701e-04 -6.752 1.46e-11 *** ## ndvi 9.653e+00 2.078e+00 4.645 3.39e-06 *** ## evi -2.322e-02 4.529e-02 -0.513 0.60822 ## nbr 8.490e+00 1.364e+00 6.226 4.80e-10 *** ## nbr2 1.347e+00 9.139e-01 1.474 0.14052 ## ndwi -1.501e+01 2.245e+00 -6.686 2.29e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 3351.1 on 3086 degrees of freedom ## Residual deviance: 1923.2 on 3079 degrees of freedom ## (3 observations deleted due to missingness) ## AIC: 1939.2 ## ## Number of Fisher Scoring iterations: 8 anova(lm_conifer) ## Analysis of Deviance Table ## ## Model: binomial, link: logit ## ## Response: absence ## ## Terms added sequentially (first to last) ## ## ## Df Deviance Resid. Df Resid. Dev ## NULL 3086 3351.1 ## blue 1 439.42 3085 2911.7 ## swir2 1 123.79 3084 2787.9 ## ndvi 1 760.09 3083 2027.8 ## evi 1 0.01 3082 2027.8 ## nbr 1 55.26 3081 1972.5 ## nbr2 1 9.51 3080 1963.0 ## ndwi 1 39.80 3079 1923.2 8.5 Random Forest rf_conifer &lt;- randomForest(absence ~ red + green + blue + nir + swir1 + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data= training_dataset %&gt;% drop_na()) randomForest::importance(rf_conifer) ## MeanDecreaseGini ## red 61.09399 ## green 63.20599 ## blue 70.04571 ## nir 52.68574 ## swir1 66.64314 ## swir2 67.75190 ## ndsi 64.38222 ## ndfsi 70.70187 ## ndvi 220.52132 ## evi 57.36789 ## nbr 79.74387 ## nbr2 59.38213 ## ndwi 169.36715 summary(rf_conifer) ## Length Class Mode ## call 3 -none- call ## type 1 -none- character ## predicted 3085 factor numeric ## err.rate 1500 -none- numeric ## confusion 6 -none- numeric ## votes 6170 matrix numeric ## oob.times 3085 -none- numeric ## classes 2 -none- character ## importance 13 -none- numeric ## importanceSD 0 -none- NULL ## localImportance 0 -none- NULL ## proximity 0 -none- NULL ## ntree 1 -none- numeric ## mtry 1 -none- numeric ## forest 14 -none- list ## y 3085 factor numeric ## test 0 -none- NULL ## inbag 0 -none- NULL ## terms 3 terms call "],["ndvi-trajectory.html", "Part 9 NDVI Trajectory 9.1 Set Up 9.2 Connect Landsat and High-Severity Patches 9.3 Prepare Dataset 9.4 Plot 9.5 Recovery", " Part 9 NDVI Trajectory 9.1 Set Up 9.1.1 Libraries library(ggplot2) library(ggthemes) library(tidyverse) library(sf) library(terra) library(raster) library(mapview) library(exactextractr) library(forcats) library(broom) 9.1.2 Import Fires # import high-severity patches patches &lt;- st_read(&quot;data/patches/highsev_patches.shp&quot;) %&gt;% st_transform(crs=&quot;EPSG: 4326&quot;) # set crs crs &lt;- crs(patches) # import fire boundaries fires_export &lt;- st_read(&quot;data/fire_boundaries/fires_export.shp&quot;)%&gt;% st_transform(., crs=crs) 9.1.3 Prepare Data for Bands and Fire Names 9.1.3.1 Bands # list band names and years bands &lt;- c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;, &quot;nir&quot;, &quot;swir1&quot;, &quot;swir2&quot;, &quot;ndvi&quot;, &quot;ndwi&quot;, &quot;nbr&quot;, &quot;nbr2&quot;, &quot;ndsi&quot;, &quot;ndfsi&quot;, &quot;evi&quot;) years &lt;- c(1984:2020) # create list of all combinations of bands, in the appropriate order bandnames &lt;- list(bands,years) %&gt;% cross() %&gt;% map(lift(paste0)) bandlist &lt;- do.call(rbind,bandnames) 9.1.3.2 Fire Names # get list of fire names fire_names &lt;- unique(fires_export$Fire_ID) 9.2 Connect Landsat and High-Severity Patches 9.2.1 Merge Rasters ## function to merge rasters, if there are multiple in the folder export_rasters &lt;- function(fire_name){ print(paste0(&quot;Starting Fire &quot;,fire_name)) # get list of this fire&#39;s tif files rast_list &lt;- list.files(path = &quot;data/landsat/landsat_annual&quot;, pattern=fire_name, all.files=TRUE, full.names=TRUE) # larger rasters were exported from GEE as multiple files, need to be combined before importing if (length(rast_list)&gt;1) { print(paste0(length(rast_list),&quot; rasters, merging...&quot;)) rast_all &lt;- lapply(rast_list, rast) rast_collection &lt;- do.call(merge,rast_all) writeRaster(rast_collection, str_c(&quot;data/landsat/landsat_annual/&quot;,fire_name,&quot;.tif&quot;), overwrite=FALSE,gdal=&quot;COMPRESS=NONE&quot;) } else { print(&quot;Only one raster, can extract directly&quot;) } } map(fire_names,export_rasters) 9.2.2 Extract Landsat Data for Each Patch extract_landsat &lt;- function(fire_name){ print(paste0(&quot;Starting Fire &quot;,fire_name)) # get list of this fire&#39;s tif files rast_list &lt;- list.files(path = &quot;data/landsat/landsat_annual&quot;, pattern=str_c(fire_name,&quot;.tif&quot;), all.files=TRUE, full.names=TRUE) rast_collection &lt;- rast(rast_list) # name the bands names(rast_collection) &lt;- bandlist # verify crs crs(rast_collection) &lt;- &quot;EPSG: 4326&quot; # filter the patches for this fire fire_patches &lt;- patches %&gt;% filter(Fire_ID==fire_name) %&gt;% st_transform(crs=crs(rast_collection)) # get the mean landsat values for each patch in this fire extracted_data &lt;- left_join(fire_patches, exact_extract(rast_collection,fire_patches, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = &quot;mean&quot;)) %&gt;% st_drop_geometry() # export return(extracted_data) } # map extraction function across all fires extracted_fires &lt;- map(fire_names,extract_landsat) # combine dataset landsat_dataset &lt;- do.call(rbind, extracted_fires) %&gt;% st_drop_geometry() 9.3 Prepare Dataset 9.3.1 Clean Data # clean dataset, label, select only ndvi, calculate pre-fire ndvi &amp; differenced ndvi ndvi_dataset_full &lt;- landsat_dataset %&gt;% mutate(Patch_ID = str_c(Fire_ID,&quot;-&quot;,1:n()), prefire_yr = as.integer(year-1), patch_area_class = fct_relevel(as.factor(case_when(ptch_r_ &gt;= 1000 ~ &quot;&gt;1000 acres&quot;, ptch_r_ &lt; 1000 &amp; ptch_r_ &gt;= 500 ~ &quot;500-1000 acres&quot;, ptch_r_ &lt; 500 &amp; ptch_r_ &gt;= 100 ~ &quot;100-500 acres&quot;, ptch_r_ &lt; 100 &amp; ptch_r_ &gt;= 50 ~ &quot;50-100 acres&quot;, ptch_r_ &lt; 50 &amp; ptch_r_ &gt;= 10 ~ &quot;10-50 acres&quot;, TRUE ~ &quot;&lt;10 acres&quot;)),&quot;&gt;1000 acres&quot;,after = 5)) %&gt;% rename(fire_yr = year, patch_area = ptch_r_, patch_foresttype = ptch_fr, Event_ID = Evnt_ID, Incid_Name = Incd_Nm, ecoregion = ecoregn) %&gt;% dplyr::select(Event_ID, Incid_Name, Fire_ID, Patch_ID, prefire_yr, fire_yr, ecoregion, patch_foresttype, patch_area, patch_area_class, contains(&quot;ndvi&quot;)) %&gt;% pivot_longer(.,contains(&quot;ndvi&quot;),names_to = &quot;landsat_yr&quot;, values_to = &quot;ndvi&quot;)%&gt;% mutate(landsat_yr = as.integer(landsat_yr %&gt;% stringr::str_remove(&quot;mean.ndvi&quot;)), years_postfire = landsat_yr - fire_yr) %&gt;% mutate(prefire_ndvi = case_when(years_postfire == -1 ~ ndvi)) %&gt;% group_by(Patch_ID) %&gt;% mutate(prefire_ndvi = mean(prefire_ndvi, na.rm=TRUE)) %&gt;% ungroup() %&gt;% mutate(delta_ndvi = ndvi - prefire_ndvi)%&gt;% filter(patch_foresttype %in% c(&quot;Lodegepole Pine&quot;,&quot;Douglas-Fir&quot;,&quot;Fir-Spruce&quot;)) # filter list to fires w/o reburning, planting, etc ndvi_dataset &lt;- ndvi_dataset_full %&gt;% filter(Fire_ID %in% c(&quot;Fire_31_1988&quot;,&quot;Fire_48_1990&quot;,&quot;Fire_18_1988&quot;,&quot;Fire_22_1988&quot;,&quot;Fire_16_1988&quot;,&quot;Fire_19_1988&quot;,&quot;Fire_20_1988&quot;,&quot;Fire_3_1988&quot;,&quot;Fire_50_1991&quot;,&quot;Fire_33_1989&quot;,&quot;Fire_26_1988&quot;,&quot;Fire_25_1988&quot;,&quot;Fire_14_1988&quot;,&quot;Fire_1_1988&quot;,&quot;Fire_11_1988&quot;,&quot;Fire_49_1991&quot;,&quot;Fire_29_1988&quot;,&quot;Fire_28_1988&quot;,&quot;Fire_7_1988&quot;,&quot;Fire_2_1988&quot;,&quot;Fire_12_1988&quot;,&quot;Fire_23_1988&quot;,&quot;Fire_38_1989&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_46_1990&quot;,&quot;Fire_51_1991&quot;,&quot;Fire_32_1989&quot;,&quot;Fire_37_1989&quot;,&quot;Fire_15_1988&quot;,&quot;Fire_9_1988&quot;,&quot;Fire_4_1988&quot;,&quot;Fire_24_1988&quot;,&quot;Fire_10_1988&quot;,&quot;Fire_41_1989&quot;,&quot;Fire_54_1991&quot;,&quot;Fire_13_1988&quot;,&quot;Fire_42_1989&quot;)) 9.3.2 Regroup Data ndvi_grouped_type &lt;- ndvi_dataset %&gt;% group_by(patch_foresttype,years_postfire) %&gt;% summarize(ndvi=mean(ndvi,na.rm=TRUE), delta_ndvi = mean(delta_ndvi,na.rm=TRUE)) %&gt;% drop_na() ndvi_grouped_size &lt;- ndvi_dataset %&gt;% group_by(patch_area_class,years_postfire) %&gt;% summarize(ndvi=mean(ndvi,na.rm=TRUE), delta_ndvi = mean(delta_ndvi,na.rm=TRUE)) %&gt;% drop_na() ndvi_grouped_ecoregion &lt;- ndvi_dataset %&gt;% group_by(ecoregion,years_postfire) %&gt;% summarize(ndvi=mean(ndvi,na.rm=TRUE), delta_ndvi = mean(delta_ndvi,na.rm=TRUE)) %&gt;% drop_na() ndvi_grouped_eco_type&lt;- ndvi_dataset %&gt;% group_by(ecoregion,patch_foresttype,years_postfire) %&gt;% summarize(ndvi=mean(ndvi,na.rm=TRUE), delta_ndvi = mean(delta_ndvi,na.rm=TRUE)) %&gt;% drop_na() 9.4 Plot 9.4.1 Forest Type # ggplot(ndvi_dataset ,aes(years_postfire,ndvi,color=patch_foresttype))+ # geom_point(size=1) + # geom_smooth(method=&quot;auto&quot;,se=FALSE) + # labs(x=&quot;Year&quot;,y=&quot;NDVI&quot;,title= &quot;All High-Severity Patch NDVI Change 30 Years Post-Fire&quot;, subtitle = &quot;Comparing Forest Types&quot;, color = &quot;Patch Forest Type&quot;) # ggplot(ndvi_grouped_type,aes(years_postfire,delta_ndvi,color=patch_foresttype,group=patch_foresttype))+ # geom_smooth(method=&quot;auto&quot;,se=FALSE) + # labs(x=&quot;Year&quot;,y=&quot;NDVI&quot;,title= &quot;All High-Severity Patch NDVI Recovery 30 Years Post-Fire&quot;, subtitle = &quot;Comparing Forest Types&quot;, color = &quot;Patch Forest Type&quot;) + # geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) # # ggplot(ndvi_grouped_type ,aes(years_postfire,ndvi,color=patch_foresttype,group=patch_foresttype))+ # geom_point(size=1) + # geom_smooth(method=&quot;auto&quot;,se=FALSE) + # labs(x=&quot;Year&quot;,y=&quot;NDVI&quot;,title= &quot;NDVI Change Overtime 30 Years Post-Fire&quot;, subtitle = &quot;Comparing Forest Types&quot;,color = &quot;Forest Type&quot;) ggplot(ndvi_grouped_type,aes(years_postfire,delta_ndvi,color=patch_foresttype,group=patch_foresttype))+ geom_point(size=1) + geom_smooth(method=&quot;auto&quot;,se=FALSE) + labs(x=&quot;Year&quot;,y=&quot;Change in NDVI from Pre-Fire&quot;,title= &quot;NDVI Change Overtime 30 Years Post-Fire&quot;, subtitle = &quot;Comparing Forest Types&quot;,color = &quot;Forest Type&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) 9.4.2 Patch Area # ggplot(ndvi_grouped_size,aes(years_postfire,ndvi,color=patch_area_class,group=patch_area_class))+ # geom_point(size=1) + # geom_smooth(se=FALSE,method=&quot;auto&quot;) + # labs(x=&quot;Year&quot;,y=&quot;NDVI&quot;,title= &quot;NDVI Change Overtime 30 Years Post-Fire&quot;, subtitle = &quot;Comparing Patch Size&quot;,color = &quot;Patch Size&quot;) ggplot(ndvi_grouped_size,aes(years_postfire,delta_ndvi,color=patch_area_class,group=patch_area_class))+ geom_point(size=1) + geom_smooth(se=FALSE,method=&quot;auto&quot;) + labs(x=&quot;Year&quot;,y=&quot;Change in NDVI from Pre-Fire&quot;,title= &quot;NDVI Change Overtime 30 Years Post-Fire&quot;, subtitle = &quot;Comparing Patch Size&quot;,color = &quot;Patch Size&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) 9.4.3 Ecoregion # ggplot(ndvi_grouped_ecoregion,aes(years_postfire,ndvi,color=ecoregion,group=ecoregion))+ # geom_point(size=1) + # geom_smooth(se=FALSE,method=&quot;auto&quot;) + # labs(x=&quot;Year&quot;,y=&quot;NDVI&quot;,title= &quot;NDVI Change Overtime 30 Years Post-Fire&quot;,subtitle= &quot;Comparing Ecoegions&quot;,color = &quot;Ecoregion&quot;) ggplot(ndvi_grouped_ecoregion,aes(years_postfire,delta_ndvi,color=ecoregion,group=ecoregion))+ geom_point(size=1) + geom_smooth(se=FALSE,method=&quot;auto&quot;) + labs(x=&quot;Year&quot;,y=&quot;Change in NDVI from Pre-Fire&quot;,title= &quot;NDVI Change Overtime 30 Years Post-Fire&quot;, subtitle= &quot;Comparing Ecoegions&quot;,color = &quot;Ecoregion&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) 9.5 Recovery 9.5.1 Forest Type ggplot(ndvi_grouped_type %&gt;% filter(years_postfire&gt;9),aes(years_postfire,delta_ndvi,color=patch_foresttype,group=patch_foresttype))+ geom_point(size=1) + geom_smooth(method=&quot;lm&quot;,se=FALSE) + labs(x=&quot;Year&quot;,y=&quot;Change in NDVI from Pre-Fire&quot;,title= &quot;NDVI Change Overtime 10-30 Years Post-Fire&quot;, subtitle = &quot;Comparing Forest Types&quot;,color = &quot;Forest Type&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) # model NDVI difference for each forest type model_ndvi &lt;- ndvi_grouped_type%&gt;% filter(years_postfire&gt;9) %&gt;% split(f = .$patch_foresttype) %&gt;% map(function(df) lm(delta_ndvi ~ years_postfire, data = df)) model_ndvi_df &lt;- as.data.frame(do.call(rbind,map(model_ndvi, coef)))%&gt;% rownames_to_column(var = &quot;patch_foresttype&quot;) %&gt;% rename(intercept = &quot;(Intercept)&quot;, slope = years_postfire) %&gt;% mutate(years_recovery = -intercept / slope) model_ndvi_df ## patch_foresttype intercept slope years_recovery ## 1 Douglas-Fir -0.2876513 0.007572175 37.98794 ## 2 Fir-Spruce -0.2610527 0.003583195 72.85473 ## 3 Lodegepole Pine -0.3079152 0.009926209 31.02043 # Print the summary of each model lapply(model_ndvi, summary) ## $`Douglas-Fir` ## ## Call: ## lm(formula = delta_ndvi ~ years_postfire, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.030514 -0.007266 0.001718 0.010075 0.023860 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.2876513 0.0101351 -28.38 &lt; 2e-16 *** ## years_postfire 0.0075722 0.0004602 16.45 1.78e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.01464 on 21 degrees of freedom ## Multiple R-squared: 0.928, Adjusted R-squared: 0.9246 ## F-statistic: 270.7 on 1 and 21 DF, p-value: 1.785e-13 ## ## ## $`Fir-Spruce` ## ## Call: ## lm(formula = delta_ndvi ~ years_postfire, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.068487 -0.004621 0.008208 0.016810 0.032244 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.2610527 0.0178472 -14.627 1.75e-12 *** ## years_postfire 0.0035832 0.0008104 4.422 0.000237 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.02578 on 21 degrees of freedom ## Multiple R-squared: 0.4821, Adjusted R-squared: 0.4575 ## F-statistic: 19.55 on 1 and 21 DF, p-value: 0.0002372 ## ## ## $`Lodegepole Pine` ## ## Call: ## lm(formula = delta_ndvi ~ years_postfire, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.043818 -0.017702 -0.000376 0.019952 0.036962 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.3079152 0.0175365 -17.56 4.98e-14 *** ## years_postfire 0.0099262 0.0007963 12.47 3.60e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.02533 on 21 degrees of freedom ## Multiple R-squared: 0.8809, Adjusted R-squared: 0.8753 ## F-statistic: 155.4 on 1 and 21 DF, p-value: 3.598e-11 9.5.2 Ecoregion ggplot(ndvi_grouped_ecoregion %&gt;% filter(years_postfire&gt;9),aes(years_postfire,delta_ndvi,color=ecoregion,group=ecoregion))+ geom_point(size=1) + geom_smooth(method=&quot;lm&quot;,se=FALSE) + labs(x=&quot;Year&quot;,y=&quot;Change in NDVI from Pre-Fire&quot;,title= &quot;NDVI Change Overtime 10-30 Years Post-Fire&quot;, subtitle = &quot;Comparing Ecoregions&quot;,color = &quot;Ecoregion&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) # model NDVI difference for each forest type model_eco &lt;- ndvi_grouped_ecoregion%&gt;% filter(years_postfire&gt;9) %&gt;% split(f = .$ecoregion) %&gt;% map(function(df) lm(delta_ndvi ~ years_postfire, data = df)) model_eco_df &lt;- as.data.frame(do.call(rbind,map(model_eco, coef)))%&gt;% rownames_to_column(var = &quot;ecoregion&quot;) %&gt;% rename(intercept = &quot;(Intercept)&quot;, slope = years_postfire) %&gt;% mutate(years_recovery = -intercept / slope) model_eco_df ## ecoregion intercept slope years_recovery ## 1 Canadian Rockies -0.2389434 0.007935738 30.10980 ## 2 Idaho Batholith -0.2554835 0.005547156 46.05666 ## 3 Middle Rockies -0.2933972 0.007477205 39.23888 ## 4 Northern Rockies -0.3041583 0.012559043 24.21827 # Print the summary of each model lapply(model_eco, summary) ## $`Canadian Rockies` ## ## Call: ## lm(formula = delta_ndvi ~ years_postfire, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.064480 -0.022832 -0.007656 0.032438 0.081773 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.238943 0.026277 -9.093 9.96e-09 *** ## years_postfire 0.007936 0.001193 6.651 1.39e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.03796 on 21 degrees of freedom ## Multiple R-squared: 0.6781, Adjusted R-squared: 0.6627 ## F-statistic: 44.23 on 1 and 21 DF, p-value: 1.389e-06 ## ## ## $`Idaho Batholith` ## ## Call: ## lm(formula = delta_ndvi ~ years_postfire, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.044750 -0.009354 0.003710 0.011723 0.035314 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.2554835 0.0136620 -18.700 1.43e-14 *** ## years_postfire 0.0055472 0.0006204 8.942 1.32e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.01973 on 21 degrees of freedom ## Multiple R-squared: 0.792, Adjusted R-squared: 0.7821 ## F-statistic: 79.96 on 1 and 21 DF, p-value: 1.322e-08 ## ## ## $`Middle Rockies` ## ## Call: ## lm(formula = delta_ndvi ~ years_postfire, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.042953 -0.017355 0.000685 0.021043 0.030923 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.2933972 0.0165676 -17.709 4.21e-14 *** ## years_postfire 0.0074772 0.0007523 9.939 2.16e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.02393 on 21 degrees of freedom ## Multiple R-squared: 0.8247, Adjusted R-squared: 0.8163 ## F-statistic: 98.79 on 1 and 21 DF, p-value: 2.156e-09 ## ## ## $`Northern Rockies` ## ## Call: ## lm(formula = delta_ndvi ~ years_postfire, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.083609 -0.014534 -0.007325 0.007496 0.085205 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.304158 0.023271 -13.07 1.48e-11 *** ## years_postfire 0.012559 0.001057 11.89 8.69e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.03361 on 21 degrees of freedom ## Multiple R-squared: 0.8706, Adjusted R-squared: 0.8644 ## F-statistic: 141.3 on 1 and 21 DF, p-value: 8.687e-11 9.5.3 Ecoregion and Forest Type ggplot(ndvi_grouped_eco_type %&gt;% filter(years_postfire&gt;9),aes(years_postfire,delta_ndvi,color=ecoregion))+ geom_point(size=1) + geom_smooth(method=&quot;lm&quot;,se=FALSE) + labs(x=&quot;Year&quot;,y=&quot;Change in NDVI from Pre-Fire&quot;,title= &quot;NDVI Change Overtime 10-30 Years Post-Fire&quot;, subtitle = &quot;Comparing Forest Types Across Ecoregions&quot;,color = &quot;Forest Type&quot;, linetype = &quot;Ecoregion&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) + facet_wrap(~ patch_foresttype) ggplot(ndvi_grouped_eco_type %&gt;% filter(years_postfire&gt;9),aes(years_postfire,delta_ndvi,color=patch_foresttype))+ geom_point(size=1) + geom_smooth(method=&quot;lm&quot;,se=FALSE) + labs(x=&quot;Year&quot;,y=&quot;Change in NDVI from Pre-Fire&quot;,title= &quot;NDVI Change Overtime 10-30 Years Post-Fire&quot;, subtitle = &quot;Comparing Forest Types Across Ecoregions&quot;,color = &quot;Forest Type&quot;, linetype = &quot;Ecoregion&quot;) + geom_hline(yintercept= 0,linetype=&quot;dashed&quot;,color=&quot;black&quot;,size=1) + facet_wrap(~ ecoregion) # model NDVI difference for each forest type model_eco_type &lt;- ndvi_grouped_eco_type%&gt;% filter(years_postfire&gt;9) %&gt;% split(f = list(.$ecoregion,.$patch_foresttype)) %&gt;% map(function(df) lm(delta_ndvi ~ years_postfire, data = df)) model_eco_type_df &lt;- as.data.frame(do.call(rbind,map(model_eco_type, coef)))%&gt;% rownames_to_column(var = &quot;ecoregion_foresttype&quot;) %&gt;% rename(intercept = &quot;(Intercept)&quot;, slope = years_postfire) %&gt;% mutate(years_recovery = -intercept / slope) %&gt;% within(., do.call(&#39;rbind&#39;, strsplit(as.character(ecoregion_foresttype), &#39;.&#39;, fixed=TRUE))) model_eco_type_df ## ecoregion_foresttype intercept slope years_recovery ## 1 Canadian Rockies.Douglas-Fir -0.2289446 0.011688508 19.58715 ## 2 Idaho Batholith.Douglas-Fir -0.2752133 0.005867322 46.90613 ## 3 Middle Rockies.Douglas-Fir -0.2970952 0.006756268 43.97327 ## 4 Northern Rockies.Douglas-Fir -0.3072955 0.013683055 22.45811 ## 5 Canadian Rockies.Fir-Spruce -0.2528835 0.006857287 36.87807 ## 6 Idaho Batholith.Fir-Spruce -0.2394074 0.005208701 45.96297 ## 7 Middle Rockies.Fir-Spruce -0.2647633 0.003282017 80.67092 ## 8 Northern Rockies.Fir-Spruce -0.2703233 0.008541474 31.64832 ## 9 Canadian Rockies.Lodegepole Pine -0.2354484 0.006569348 35.84045 ## 10 Idaho Batholith.Lodegepole Pine -0.2614338 0.006178923 42.31057 ## 11 Middle Rockies.Lodegepole Pine -0.3099012 0.010021384 30.92399 ## 12 Northern Rockies.Lodegepole Pine -0.3156453 0.012472322 25.30766 # Print the summary of each model # lapply(model_eco_type, summary) # # model NDVI difference for each forest type # models &lt;- dlply(ndvi_dataset%&gt;% filter(years_postfire&gt;9), &quot;patch_foresttype&quot;, function(df) # lmer(delta_ndvi ~ years_postfire + (1|Fire_ID), data = df, REML=TRUE)) # # # apply coef to each model and return a data frame # model_coef_df &lt;- coef(models$`Douglas-Fir`) # model_coef_df # # summary(models$`Douglas-Fir`) # # colnames(model_coef_df) &lt;- c(&quot;patch_foresttype&quot;,&quot;intercept&quot;,&quot;years_slope&quot;) # # model_coef &lt;- model_coef_df%&gt;% # mutate(years_recovery = -intercept / years_slope) # model_coef # # # Print the summary of each model # model_sums &lt;- l_ply(models, summary, .print = TRUE) # ggplotRegression &lt;- function (fit) { # ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) + # geom_point() + # stat_smooth(method = &quot;lm&quot;, col = &quot;red&quot;) + # labs(title = paste(&quot;Adj R2 = &quot;,signif(summary(fit)$adj.r.squared, 5), # &quot;Intercept =&quot;,signif(fit$coef[[1]],5 ), # &quot; Slope =&quot;,signif(fit$coef[[2]], 5), # &quot; P =&quot;,signif(summary(fit)$coef[2,4], 5))) # } # # # ggplotRegression(fitted_models[1]$model) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
