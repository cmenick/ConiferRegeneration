--- 
title: "Post-Fire Conifer Regeneration"
author: "Casey Menick"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib]
description: 
output: html_document
link-citations: yes
github-repo: rstudio/bookdown-demo
always_allow_html: true
---

# About

There has been an increasing number of large, high-severity wildfires across the Western United States. It is not fully understood how this intensification may impact conifer forests of the West, whose resilience is dependent on successful seedling regeneration. It is important to understand how these forests are able to recolonize high-severity burn patches and subsequently respond to these shifting disturbance regimes. The goal of this research is to characterize the 30-year recovery trajectory and spatial pattern of conifer regeneration within high-severity burn patches. We investigated 35 high-severity wildfire complexes that occurred between 1988 and 1991 in conifer-dominated ecosystems of the northern Rocky Mountains. Composite snow-cover Landsat imagery was utilized to isolate conifer-specific vegetation and diminish spectral contributions from deciduous vegetation. Conifer regeneration was determined to be initially detectable by Landsat approximately 10-years post-fire using these methods. The presence of conifer regeneration was then modeled at 3-year intervals post-fire to characterize the progression of recolonization. The trajectory of snow-cover Landsat NDVI was utilized to estimate recovery time to pre-fire vegetation conditions for Douglas-fir, Fir-Spruce, and lodgepole pine forests. Ongoing analysis will determine the level of regeneration cover in a Landsat pixel for detection and characterize how spatial patterns of colonization vary across burn patch size and species. This work will provide insights into the ecological processes of conifer regeneration and may be applied to support forest restoration decision making following high-severity wildfire.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->


# Fire Selection

## Set Up

### Libraries

```{r libraries1, message=FALSE, warning=FALSE}
library(tidyverse)
library(terra)
library(sf)
library(mapview)
library(raster)
library(rgeos)
library(lubridate)
library(ggplot2)
library(exactextractr)
library(patchwoRk)
library(gridExtra)
library(knitr)
library(rasterVis)
library(RColorBrewer)

```

### USDA National Forest Type Group Dataset
Conifer Forest Type Groups: Douglas-Fir, Fir-Spruce-Mountain Hemlock, Lodgepole Pine

```{r import forest type groups, message=FALSE, warning=FALSE, results='hide'}
# forest type groups and key
conus_forestgroup <- raster('data/forest_type/conus_forestgroup.tif')
forest_codes <- read_csv('data/forest_type/forestgroupcodes.csv')

# set crs
crs = crs(conus_forestgroup)
```

### EPA level-3 Ecoregions
Canadian Rockies, Idaho Batholith, Middle Rockies, Columbian Mountains - Northern Rockies
```{r ecoregions, message=FALSE, warning=FALSE, results='hide'}
# level 3 ecoregions
l3eco <- st_read('data/ecoregion/us_eco_l3.shp') %>% 
  st_transform(., crs=crs)

# select northern rocky mountains from level3 ecoregions
eco_select <- l3eco %>% 
  filter(NA_L3NAME %in% c('Canadian Rockies','Columbia Mountains/Northern Rockies','Middle Rockies','Idaho Batholith'))
```

### Mapping

#### Ecoregions

```{r mapping ecoregion, message=FALSE, warning=FALSE}
# mapview
palette <- brewer.pal(18,"YlGn")
palette[1] <- rgb(255, 255, 255, maxColorValue=255, alpha=1)
mapview(eco_select,na.color=palette[1],legend=TRUE)
```

#### Forest Type Groups

```{r mapping ftype, message=FALSE, warning=FALSE}
# convert raster values to factors
forestgroup_eco <- crop(conus_forestgroup,eco_select) %>% 
  mask(.,eco_select) %>% 
  as.factor()

# add a labels for forest type code 
group_levels <- levels(forestgroup_eco)[[1]]
group_levels[["forest_type"]] <- c("0: Unforested","120: Spruce/Fir","180: Pinyon/Juniper","200: Douglas-fir","220: Ponderosa Pine","240: Western White Pine","260: Fir/Spruce/Mountain Hemlock","280: Lodgepole Pine","300: Hemlock/Sitka Spruce","320: Western Larch","360: Other Western Softwood","370: California Mixed Conifer","400: Oak/Pine","500: Oak/Hickory","700: Elm/Ash/Cottonwood","900: Aspen/Birch","920: Western Oak","950: Other Western Hardwoods")

levels(forestgroup_eco) <- group_levels

# mapview
mapview(forestgroup_eco, col.regions=palette,na.color=palette[1],legend=TRUE)
```

## Define Fire Parameters

### Monitoring Trends in Burn Severity (MTBS) Dataset

Criteria: 

  -1988-1991

  -500+ acres of high-severity

  -Within selected ecoregions

  ->25% of selected forest types
  
```{r import mtbs, message=FALSE, warning=FALSE, results='hide',cache = TRUE}
# mtbs fire perimeters
mtbs_full <- st_read('data/mtbs/mtbs_perims_DD.shp') %>% 
  st_transform(., crs=crs)

mtbs_select <- mtbs_full %>% 
  mutate(state = str_sub(Event_ID,0,2),
         year = year(as.Date(Ig_Date))) %>% 
  filter(state %in% c("WA","ID","MT","WY","SD"),
         between(Ig_Date, as.Date('1988-01-1'), as.Date('1991-12-31'))) 
```
### Group Adjacent Fires

```{r create polygon grouping function}
# function to group adjoining fire polygons to ensure contiguous high-severity patches
group_fires <- function(mtbs_year) {

  # join the polygons with themselves, and remove those that do not join with any besides themselves
  combined<- st_join(mtbs_year, mtbs_year, join=st_is_within_distance, dist = 180, left = TRUE,remove_self = TRUE) %>% 
    drop_na(Event_ID.y)%>% 
    dplyr::select(Event_ID.x,Event_ID.y)
  
  if(nrow(combined)>=1){ # if there are overlaps for this years fires...
    
    # partition data into that that has overlap, and that that does not
    overlap <- mtbs_year %>%
      filter(Event_ID %in% combined$Event_ID.x)
    no_overlap <- mtbs_year %>%
      filter(!(Event_ID %in% combined$Event_ID.x))
    
    print(paste0("there are ",nrow(overlap)," overlapping polygons"))
    
    # join all overlapping features, and buffer to ensure proper grouping
    overlap_union <- st_union(overlap) %>%
      st_buffer(190)
    
    # break apart the joined polygons into their individual groups
    groups <- st_as_sf(st_cast(overlap_union ,to='POLYGON',group_or_split=TRUE)) %>%
      mutate(year = mean(mtbs_year$year),
             Fire_ID = str_c("Fire_",c(1:nrow(.)),"_",year)) %>%
      rename(geometry = x)
    
    print(paste0("polygons formed into ",nrow(groups)," groups"))
    
    # join back with original dataset to return to unbuffered geometry
    grouped_overlap <- st_join(overlap,groups,left=TRUE)
    
    # arrange by the new grouping
    joined_overlap_groups <- grouped_overlap %>%
      group_by(Fire_ID) %>%
      tally()%>%
      st_buffer(1) %>%
      dplyr::select(Fire_ID) %>%
      mutate(year = mean(mtbs_year$year))
    
    # add new ID to the freestanding polygons
    no_overlap_groups <- no_overlap %>%
      mutate(Fire_ID = str_c("Fire_",nrow(groups)+c(1:nrow(no_overlap)),"_",year)) %>%
      dplyr::select(Fire_ID,year)
    
    # join the new grouped overlap and the polygons without overlap
    fires_export <- rbind(joined_overlap_groups,no_overlap_groups)
    return(fires_export)
    
    } else { # if there are no overlaps for this year...
      
      print("no overlapping polygons")
      
      fires_export <- mtbs_year %>%
        mutate(Fire_ID = str_c("Fire_",c(1:nrow(.)),"_",year)) %>%
        dplyr::select(Fire_ID,year)
      
      return(fires_export)
  }
}
```

```{r group adjacent or overlapping polygons, message=FALSE, warning=FALSE, cache=TRUE}
# group adjacent polygons within each fire year
fires_88 <- group_fires(mtbs_select %>%  filter(year == 1988))
fires_89 <- group_fires(mtbs_select %>%  filter(year == 1989))
fires_90 <- group_fires(mtbs_select %>%  filter(year == 1990))
fires_91 <- group_fires(mtbs_select %>%  filter(year == 1991))

# join each fire year, filter by area
mtbs_grouped <- rbind(fires_88,fires_89,fires_90,fires_91)%>%
  mutate(area_ha = as.numeric(st_area(geometry))/10000,
         area_acres = area_ha*2.471)
```
### Select Fires by Ecoregion and Forest Type 

```{r forest typing, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
# assign ecoregion and proportions of forest type to each fire polygon
fires_join <- st_join(mtbs_grouped,eco_select,join=st_intersects,left=FALSE,largest=TRUE) %>% 
  left_join(., exact_extract(conus_forestgroup,mtbs_grouped, append_cols = TRUE, max_cells_in_memory = 3e+08, 
                             fun = function(value, coverage_fraction) {
                               data.frame(value = value,
                                          frac = coverage_fraction / sum(coverage_fraction)) %>%
                                 group_by(value) %>%
                                 summarize(freq = sum(frac), .groups = 'drop') %>%
                                 pivot_wider(names_from = 'value',
                                             names_prefix = 'freq_',
                                             values_from = 'freq')}) %>%
              mutate(across(starts_with('freq'), replace_na, 0)))
 
# remove unnecessary columns, cleanup names
# filter to ensure fire polygons are at least 25% type of interest
fires <- fires_join %>% 
  dplyr::select("Fire_ID","year","area_ha","area_acres","US_L3NAME","freq_0","freq_200","freq_220","freq_260","freq_280") %>% 
  rename("ecoregion" = "US_L3NAME",
         "freq_df"="freq_200",
         "freq_pp"="freq_220",
         "freq_fs"="freq_260",
         "freq_lpp"="freq_280") %>% 
  mutate(freq_allother = 1-(freq_0 + freq_df+freq_pp+freq_fs+freq_lpp),
         freq_forested = 1- freq_0,
         freq_ideal = freq_df+freq_fs+freq_lpp)%>% 
  mutate(across(starts_with('freq'), round,2))%>% 
  filter(freq_ideal > 0.25)
```
### Select Fires by Burn Severity

```{r extract burn severity, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
# import all mtbs rasters via a list
rastlist <- list.files(path = "data/mtbs", pattern='.tif', all.files=TRUE, full.names=TRUE)
allrasters <- lapply(rastlist, raster)
names(allrasters) <- str_c("y", str_sub(rastlist,22,25))

# create empty dataframe
severity_list <- list()

# loop through mtbs mosasics for 1988-1991
# extract mtbs burn severity raster for all selected fires
# calculate burn severity percentages for each fire
for (i in names(allrasters)){
  mtbs_year <- allrasters[[i]]
  fire_year <- filter(fires, year==str_sub(i,2,5)) 
  raster_extract <- exact_extract(mtbs_year,fire_year, max_cells_in_memory = 3e+09,coverage_area=TRUE)
  names(raster_extract) <- fire_year$Fire_ID 
  
  output_select <- bind_rows(raster_extract, .id = "Fire_ID")%>%
    group_by(Fire_ID , value) %>%
    summarize(total_area = sum(coverage_area)) %>%
    group_by(Fire_ID) %>%
    mutate(proportion = total_area/sum(total_area))%>% 
    dplyr::select("Fire_ID","value","proportion") %>% 
    spread(.,key="value",value = "proportion")
  
  severity_list[[i]] <- output_select
}

# combine extracted raster datasets
severity_df <- do.call(rbind, severity_list) 

# join burn severity % to fires polygons
# fix naming
# filter dataset for 500 acres high severity
fires_severity <- left_join(fires,severity_df,by="Fire_ID")%>% 
  rename(noburn= "1",lowsev = "2", medsev = "3", highsev = "4",regrowth = "5", error = "6") %>% 
  dplyr::select(- "NaN",-"regrowth",-"error") %>% 
  mutate(highsev_acres = area_acres*highsev)%>% 
  filter(highsev_acres > 500)
```
### Clean Up Dataset
```{r extract majority forest type, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
# get the most common forest type within each polygon
fires_select <- fires_severity %>%
  left_join(.,exact_extract(conus_forestgroup,fires_severity, 'mode', append_cols = TRUE, max_cells_in_memory = 3e+08)) 

fires_select$mode <- as.factor(fires_select$mode)

fires_select <- fires_select %>% 
    mutate(fire_foresttype = case_when(mode==200 ~ "Douglas-Fir",
                                       mode==220 ~ "Ponderosa",
                                       mode==260 ~ "Fir-Spruce",
                                       mode==280 ~ "Lodegepole Pine",
                                       TRUE ~ "Other"),
           Fire_ID = str_c("Fire_",c(1:nrow(.)),"_",year))
```

```{r get mtbs fires, message=FALSE, warning=FALSE, cache=TRUE}
# join the grouped fires back to original mtbs boundaries
fires_mtbs <- st_join(mtbs_select,fires_select,left=FALSE,largest=TRUE) %>% 
  filter(year.x==year.y)%>% 
  dplyr::select("Event_ID","Incid_Name","Fire_ID","Ig_Date","year.y","state","BurnBndAc","ecoregion") %>% 
  rename(year= year.y)
```

## Final Fire Dataset

### Dataset Overview

```{r}
full_dataset <- fires_select %>% 
  st_drop_geometry() %>% 
  dplyr::select(Fire_ID,year,ecoregion,fire_foresttype,area_acres,highsev) %>% 
  mutate(highsev = round(highsev,2),
         area_acres = round(area_acres,0))  

kable(full_dataset, 
      align = 'c',
      padding = 1,
      col.names = c("Fire ID", "Year", "Ecoregion", "Majority Forest Type","Area (acres)", "High Severity %"),
      caption = "High-Severity Conifer-Dominated Fires 1988-1991")
```


## Mapping

### Selected fires by year
```{r plot year}
# plot
mapview(fires_select, zcol = "year")
```

### Selected fires by majority forest type
```{r plot forest type}
# plot
mapview(fires_select, zcol = "fire_foresttype")
```

### Final Fires

```{r}
fire_names <- c("Fire_1_1988","Fire_2_1988","Fire_3_1988","Fire_4_1988","Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_54_1991")

mapview(forestgroup_eco, col.regions=palette,na.color=palette[1],legend=TRUE) +
  mapview(fires_select %>% filter(Fire_ID %in% fire_names),col.regions="black",alpha.regions=100) +
  mapview(st_union(eco_select), col.regions = "blue", alpha.regions = 0)
```


## Export Data 

### Final Cleanup for Export
```{r cleanup, message=FALSE, warning=FALSE}
# reformat and project
fires_export <- fires_select %>% 
  mutate(year = as.integer(year)) %>% 
  st_transform(., crs="EPSG:4326")

mtbs_export <- fires_mtbs %>% 
  mutate(year = as.integer(year)) %>% 
  st_transform(., crs="EPSG:4326")
```

### Export
```{r export fire boundaries}
# st_write(fires_export, "data/fire_boundaries/", "fires_export.shp", driver = 'ESRI Shapefile')
# st_write(mtbs_export, "data/fire_boundaries/", "mbts_export.shp", driver = 'ESRI Shapefile')
```



<!--chapter:end:01_fireselection.Rmd-->

# Calculation of High-Severity

## Set Up

### Import Fire Boundaries
```{js import boundaries}
var mtbs_all = ee.FeatureCollection("USFS/GTAC/MTBS/burned_area_boundaries/v1");
    
var fires = ee.FeatureCollection("projects/westernconiferregen/assets/fires_export");
```

### Clean Fire Boundaries

```{js clean boundaries}
// filter mtbs fire perimeters to relevant date range
var mtbs = mtbs_all
  .filter(ee.Filter.gt("Ig_Date",ee.Date('1984-01-01').millis()))
  .filter(ee.Filter.lt("Ig_Date",ee.Date('1992-12-31').millis()));
	
// list fire IDs and get total number of fires
var fireID = ee.List(fires.aggregate_array('Fire_ID')).getInfo();
var nFires = fireID.length;
```

## Imagery 

### Import Landsat 5

```{js get landsat}
// Landsat 5 Surface Reflectance Tier 1 collection
var ls5_SR = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR');
```

### Prepare Landsat Data

```{js clean landsat}
// function to get NBR, qa pixel bands
var ls5_getbands = function(lsImage){
  var nbr = lsImage.normalizedDifference(['B4', 'B7']).toFloat();
  var qa = lsImage.select(['pixel_qa']);
  return nbr.addBands([qa])
          .select([0,1], ['nbr', 'pixel_qa'])
          .copyProperties(lsImage, ['system:time_start']);
  };

// function to get clear pixels
var ls5_qa = function(lsImg){
  var quality =lsImg.select(['pixel_qa']);
  var clear = quality.bitwiseAnd(8).eq(0) // cloud shadow
                .and(quality.bitwiseAnd(32).eq(0) // cloud
                .and(quality.bitwiseAnd(4).eq(0) // water
                .and(quality.bitwiseAnd(16).eq(0)))); // snow
  return lsImg.updateMask(clear).select([0])                                    
            .copyProperties(lsImg, ['system:time_start']);
};

// function to project to EPSG 4326
var ls5_project = function(lsImage){
  var proj4326 = ee.Projection('EPSG:4326').atScale(30);
  var lsImage_proj = lsImage.reproject(proj4326);
  return lsImage_proj;
};

// Map functions across Landsat Collection
var ls5 = ls5_SR.map(ls5_getbands)
               .map(ls5_qa)
               .map(ls5_project);
```

## Burn Indices

### Calculate RdNBR

```{js calculate RdNBR}
// Calculate burn severity metrics for each fire
var indices = ee.ImageCollection(fires.map(function(fire){

  // get fire bounds
  var fireBounds = fire.geometry().bounds();
  
  // get pre- and post-fire years
  var fireYear = ee.Date.parse('YYYY', fire.get('year'));
  var preFireYear = fireYear.advance(-1, 'year'); 
  var postFireYear = fireYear.advance(1, 'year');
  
  // filter ls5 to fire bounds and dates to get pre and post-fire imagery
  var preNBR = ls5.filterBounds(fireBounds)
                          .filterDate(preFireYear, fireYear)
                          .filter(ee.Filter.dayOfYear(152, 273))
                          .mean()
                          .rename('preNBR');
 
  var postNBR = ls5.filterBounds(fireBounds)
                          .filterDate(postFireYear, fireYear.advance(2, 'year'))
                          .filter(ee.Filter.dayOfYear(152, 273))
                          .mean()
                          .rename('postNBR');
  
  // calculate sqrt of pre-fire NBR to relativize
  var preNBRsq = preNBR
            .expression("abs(b('preNBR')) < 0.001 ? 0.001" + ": b('preNBR')")
            .abs().sqrt().rename('preNBRsq').toFloat();
  
  // combine pre and post-fire imagery                       
  var fireIndices = preNBR.addBands(postNBR).addBands(preNBRsq);
  
  // calculate dNBR  
  var dnbr = fireIndices.expression("(b('preNBR') - b('postNBR')) * 1000").rename('dnbr').toFloat();

  // calculate offset value from 180-m buffer of unburned area outside the fire perimeter
  var ring   = fire.buffer(180).difference(mtbs.geometry());
  
  var offset = ee.Image.constant(ee.Number(dnbr.select('dnbr').reduceRegion({
      reducer: ee.Reducer.mean(),
      geometry: ring.geometry(),
      scale: 30,
      maxPixels: 1e9
    }).get('dnbr'))).rename('offset').toFloat().addBands(dnbr);

  // calculate dNBR with offset
  var dnbr_w_offset = fireIndices
          .addBands(offset.expression("b('dnbr') - b('offset')").rename('dnbr_w_offset').toFloat());

  // calculate RdNBR with offset
  var rdnbr_w_offset = dnbr_w_offset.expression("b('dnbr_w_offset') / b('preNBRsq')").rename('rdnbr_w_offset').toFloat();

  return rdnbr_w_offset.select('rdnbr_w_offset').set({'fireID': fire.get('Fire_ID'),'fireYear': fire.get('year')
  }); 
}));
```

## Export

### Export Each Fire RdNBR to Drive
```{js export rdnbr}
// export to drive
for (var j = 0; j < nFires; j++){
  var id   = fireID[j];
  var Name = id;
  var fireExport = ee.Image(indices.filterMetadata('fireID', 'equals', id).first());
  var fireBounds = ee.Feature(fires.filterMetadata('Fire_ID', 'equals', id).first()).geometry().bounds();
  var firePolygon = ee.Feature(fires.filterMetadata('Fire_ID', 'equals', id).first()).geometry();

  var exportImg = fireExport.select('rdnbr_w_offset').toInt().clip(firePolygon);
  
  Export.image.toDrive({
    image: exportImg,
    folder: "fire_rdnbr_rasters",
    description: Name,
    crs: "EPSG:4326",
    maxPixels: 1e13,
    scale: 30,
    region: fireBounds
}); 
}
```


<!--chapter:end:02_rdnbr.Rmd-->


# Patch Formation

## Set Up

### Libraries
```{r libraries2, message=FALSE, warning=FALSE}
library(tidyverse)
library(terra)
library(patchwoRk)
library(sf)
library(mapview)
library(exactextractr)
library(lubridate)
```

### Import RdNBR Rasters

```{r raster import}
# import calculated RdNBR rasters for each fire boundary polygon
rast_list <- list.files(path = "data/rdnbr_rasters", pattern='.tif', all.files=TRUE, full.names=TRUE)
rast_all <- lapply(rast_list, rast)
rast_collection <- sprc(rast_all)

crs <- crs(rast_collection[1])
```

### Import Fire Boundaries

```{r fire import, message=FALSE, warning=FALSE, results='hide'}
# import fire boundaries
mtbs_export <- st_read('data/fire_boundaries/mtbs_export.shp') %>% 
  st_transform(., crs=crs) 

fires_export <- st_read("data/fire_boundaries/fires_export.shp")%>% 
  st_transform(., crs=crs)

# import forest type group raster
conus_forestgroup <- raster('data/forest_type/conus_forestgroup.tif')
forest_codes <- read_csv('data/forest_type/forestgroupcodes.csv')
```

## Create High-Severity Patches

### PatchMorph
```{r patchmorph, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
# loop through RdNBR rasters, assign >640 to high severity category
# utilize patchmorph to act as 3x3 cell majority filter
patch_df <- list()
for (i in 1:length(rast_all)){
  # print(i)
  rast_fire <- raster(rast_collection[i])
  rast_fire[rast_fire < 640] <- 0
  rast_fire[rast_fire >= 640] <- 1

  patch <- patchMorph(rast_fire, spurThresh = 3, gapThresh = 3)
  patch_poly <- as.polygons(rast(patch)) %>%
    st_as_sf()
  df_union_cast <- patch_poly %>%
    st_cast(., "POLYGON") %>%
    filter(layer == 1)
  patch_df[[i]] <- df_union_cast}

patch_poly_all <- do.call(rbind,patch_df)
```

## Refine Patches

```{r patch filter, message=FALSE, warning=FALSE}
# filter small patches
patches_full <- patch_poly_all %>% 
  mutate(patch_area_ha = as.numeric(st_area(.))/10000) %>%
  filter(patch_area_ha > 2.25)
```

```{r inform patches, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
# join patches back to grouped fires
patches_joined <- st_join(patches_full,mtbs_export,join = st_intersects,left= FALSE,largest = TRUE) %>%
  dplyr::select(-layer,-BurnBndAc) %>% 
  left_join(.,exact_extract(conus_forestgroup,., 'mode', append_cols = TRUE, max_cells_in_memory = 3e+08))%>%
  mutate(patch_foresttype = case_when(mode==200 ~ "Douglas-Fir",
                                     mode==220 ~ "Ponderosa",
                                     mode==260 ~ "Fir-Spruce",
                                     mode==280 ~ "Lodegepole Pine",
                                     mode==0 ~ "Unforested",
                                     TRUE ~ "Other"))
```

## Mapping

```{r map}
mapview(patches_joined,col.regions = "red") + mapview(fires_export, alpha.regions = 0, lwd = 2)
```


## Export Data 

```{r export patches, message=FALSE, warning=FALSE}
patches <- patches_joined %>%
  st_transform(crs = crs)

# st_write(patches, "data/patches/", "highsev_patches.shp",driver = 'ESRI Shapefile')
```

<!--chapter:end:03_patchformation.Rmd-->


# Sampling Quadrants

## Set Up

### Libraries

```{r libraries3, message=FALSE, warning=FALSE}
library(elevatr)
library(tidyverse)
library(sf)
library(terra)
library(mapview)
```

### Import High-Severity Patches and Fire Boundaries

```{r boundary import, message=FALSE, warning=FALSE, results='hide'}
# data import
patches <- st_read("data/patches/highsev_patches.shp") %>% 
  st_transform(crs="EPSG:4326")
crs <- crs(patches)

patch_interiors<- st_read("data/patches/highsev_patches_interior.shp") %>%
  st_transform(crs=crs)
patch_exteriors<- st_read("data/patches/highsev_patches_exterior.shp") %>%
  st_transform(crs=crs)

mtbs_export <- st_read('data/fire_boundaries/mtbs_export.shp') %>% 
  st_transform(crs=crs) 

fires_export <- st_read("data/fire_boundaries/fires_export.shp")%>% 
  st_transform(crs=crs)
```

## Create Sampling Quadrants

### Split Patches by North/South Aspects and Interior/Exterior

```{r quadrant creation, message=FALSE, warning=FALSE, results='hide', cache=TRUE}
# create list of fire IDs
fire_list <- unique(patches$Evnt_ID)

quadrants_df = list()

for(i in fire_list){
  
  # filter patch interiors/exteriors to the selected fire
  patch_fire <- patches %>% 
    filter(Evnt_ID == i)
  
  mapview(patch_fire)
  
  patches_interior <- patch_interiors %>% 
    filter(Evnt_ID == i)%>% 
    st_make_valid() %>% 
    st_union()
  
  patches_exterior <- patch_exteriors %>% 
    filter(Evnt_ID_1 == i)%>% 
    st_make_valid()%>% 
    st_union()
  
  # set event and fire id to the selected fire
  Evnt_ID <- i
  Fire_ID <-names(which.max(table(patch_fire$Fire_ID)))
  
  print(paste0("starting event ",Evnt_ID," in fire group ", Fire_ID))
  
  # get and calculate cosine corrected aspect
  dem <- get_elev_raster(patch_fire,z=11)
  aspect <- terrain(dem, opt = "aspect",unit = "radians")
  ccaspect <- cos(aspect)

  # positive aspects are north-facing, negative are south-facing
  ccaspect[ccaspect>0] <- 1
  ccaspect[ccaspect<0] <- -1
  ccaspect_poly <- as.polygons(rast(ccaspect)) %>%
    st_as_sf()
  
  pos_aspect <- ccaspect_poly %>%
    filter(layer==1)%>% 
    st_make_valid()
  neg_aspect <- ccaspect_poly %>%
    filter(layer==-1) %>% 
    st_make_valid()

  # get quadrants as the intersection of interior/exterior and pos/neg aspect
  pos_ext <- st_intersection(patches_exterior,pos_aspect)%>% 
    st_make_valid() %>% 
    st_union() %>% 
    st_as_sf()%>% 
    mutate(quadrant = "pos_ext",
           Evnt_ID = i,
           quad_id_event = paste0(Evnt_ID,"-",quadrant),
           Fire_ID = Fire_ID,
           quad_id_fire = paste0(Fire_ID,"-",quadrant))

  pos_int <- st_intersection(patches_interior,pos_aspect)%>% 
    st_make_valid() %>% 
    st_union()%>% 
    st_as_sf()%>% 
    mutate(quadrant = "pos_int",
           Evnt_ID = i,
           quad_id_event = paste0(Evnt_ID,"-",quadrant),
           Fire_ID = Fire_ID,
           quad_id_fire = paste0(Fire_ID,"-",quadrant))
  
  neg_ext <- st_intersection(patches_exterior,neg_aspect)%>% 
    st_make_valid() %>%
    st_union() %>% 
    st_as_sf()%>% 
    mutate(quadrant = "neg_ext",
           Evnt_ID = i,
           quad_id_event = paste0(Evnt_ID,"-",quadrant),
           Fire_ID = Fire_ID,
           quad_id_fire = paste0(Fire_ID,"-",quadrant))
  
  neg_int <- st_intersection(patches_interior, neg_aspect)%>% 
    st_make_valid() %>%
    st_union() %>% 
    st_as_sf()%>% 
    mutate(quadrant = "neg_int",
           Evnt_ID = i,
           quad_id_event = paste0(Evnt_ID,"-",quadrant),
           Fire_ID = Fire_ID,
           quad_id_fire = paste0(Fire_ID,"-",quadrant))
  
  # combine, export quadrants
  all_quadrants <- rbind(neg_int,pos_int,neg_ext,pos_ext) %>% 
    st_transform(crs=crs)

  quadrants_df[[i]] <- all_quadrants
  
  print(paste0("completed"))
}

# bind list together
quadrants_fullset <- do.call(rbind,quadrants_df) %>% 
  st_as_sf() 
```

### Clean Quadrants

```{r clean up quadrants, message=FALSE, warning=FALSE, results='hide'}
# removes erroneous polygons created from irregular fire boundary shapes
# removes small border mismatched fire
quadrants_clean <- quadrants_fullset %>% 
  mutate(area=as.numeric(st_area(x))) %>% 
  filter(area > 1) %>% 
  group_by(Evnt_ID) %>% 
  mutate(n=n()) %>% 
  filter(n == 4)

# clean up for export
quadrants_export <- quadrants_clean %>% 
  st_make_valid() %>% 
  st_as_sf() %>% 
  dplyr::select(-"area")%>% 
  st_transform(crs=crs)
```

## Export Data

```{r export quadrants, message=FALSE, warning=FALSE}
# st_write(quadrants_export,"data/patches/","quadrants_export.shp",driver = "ESRI Shapefile")
```

<!--chapter:end:04_samplingquadrants.Rmd-->

# Training Data

## Set Up

#### Libraries

```{r libraries4, message=FALSE, warning=FALSE}
library(tidyverse)
library(sf)
library(terra)
```

### Fire List

```{r}
fire_list <- c("Fire_1_1988","Fire_2_1988","Fire_3_1988","Fire_4_1988","Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_54_1991")
```


## Import Data

```{r patch import, message=FALSE, warning=FALSE, results='hide',cache = TRUE}
patches <- st_read("data/patches/highsev_patches.shp") %>% 
  st_transform(crs="EPSG: 4326")

crs <- crs(patches)

quadrants <- st_read("data/patches/quadrants_export.shp") %>% 
  st_transform(crs=crs)
```

## Sampling Points

### Import and Combine Training Points

```{r combine training points, message=FALSE, results='hide',cache=TRUE}
# list and combine training data points
points_list <- list.files(path = "data/points/individual_fire_points/", pattern='.shp', all.files=TRUE, full.names=TRUE)
points_all <- lapply(points_list, st_read)

points <- do.call(rbind,points_all) %>% 
  st_transform(crs=crs)
```

### Assign Points and Clean Data

```{r join points, message=FALSE, warning=FALSE, cache=TRUE,eval = FALSE}
# join points dataset back to fires to fill out dataset
points_joined <- st_join(points,patches,left=TRUE,largest=TRUE) %>% 
  st_join(.,quadrants,left=TRUE,largest=TRUE)

points_cleaned <- points_joined %>% 
  dplyr::select("class","ptch_r_","Evnt_ID.x","Incd_Nm","Fire_ID.x","year","ecoregn","ptch_fr","quadrnt","qd_d_vn","qd_d_fr") %>%   rename(patch_area_ha = ptch_r_,
         Event_ID = Evnt_ID.x,
         Incid_Name = Incd_Nm,
         Fire_ID = Fire_ID.x,
         patch_frtype = ptch_fr,
         quad = quadrnt,
         quad_event_id= qd_d_vn,
         quad_fire_id=qd_d_fr) %>% 
  filter(Fire_ID %in% fire_list) %>% 
  st_transform(crs=crs)
```

## Export Data

```{r export points, message=FALSE, warning=FALSE}
# st_write(points_cleaned, "data/points/", "points_export.shp",driver = 'ESRI Shapefile')
```

<!--chapter:end:05_trainingdata.Rmd-->

# Snow Cover Imagery

## Set Up

### Import Fire Boundaries
```{js import fire boundaries}
// import fire polygons
var fires_export = ee.FeatureCollection("projects/westernconiferregen/assets/fires_export");

var fires_export_buffer1500 = ee.FeatureCollection("projects/westernconiferregen/assets/fires_export_buffer1500");
```

### Import Landsat Imagery

```{js import landsat}
// import Landsat 4,5,7, rename bands
var ls7 = ee.ImageCollection('LANDSAT/LE07/C01/T1_SR'),
    ls5 = ee.ImageCollection('LANDSAT/LT05/C01/T1_SR'),
    ls4 = ee.ImageCollection('LANDSAT/LT04/C01/T1_SR');
var ls4_7 = ee.ImageCollection(ls7.merge(ls5).merge(ls4)).map(function(image) {
    var bands = ['B1','B2', 'B3', 'B4', 'B5', 'B7', 'pixel_qa']; 
    var new_bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'pixel_qa'];
    return image.select(bands).rename(new_bands);
    });

// import Landsat 8, rename bands
var ls8 = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').map(function(image) {
    var bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'pixel_qa']; 
    var new_bands = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'pixel_qa'];
    return image.select(bands).rename(new_bands);
    });

// merge Landsat 4-7 and 8 with renamed bands
var ls4_8 = ee.ImageCollection(ls8.merge(ls4_7));
```

## Create Snow-Cover Landsat Collection

### Functions to Prepare Images

#### Get Spectral Indices
```{js indices}
// function: get spectral indices
var calc_indices = function(image) {
  return image
    .addBands(image.normalizedDifference(['nir', 'red']).double().rename('ndvi'))
    .addBands(image.normalizedDifference(['green', 'nir']).double().rename('ndwi'))
    .addBands(image.normalizedDifference(['nir', 'swir2']).double().rename('nbr'))
    .addBands(image.normalizedDifference(['swir1','swir2']).double().rename('nbr2'))
    .addBands(image.normalizedDifference(['green', 'swir1']).double().rename('ndsi'))
    .addBands(image.normalizedDifference(['nir','swir1']).double().rename('ndfsi'))
    .addBands(image.expression('2.5 * ((NIR - R) / (NIR + 6 * R - 7.5 * B + 1))'
       ,{'NIR':image.select('nir'),'R':image.select('red'),'B':image.select('blue')}).rename('evi'))};
```

#### Get Clear Images

```{js qa}
// function: pixel QA for clouds and bodies of water
var qa_mask = function(lsImg){
  var quality =lsImg.select(['pixel_qa']);
  var clear = quality.bitwiseAnd(8).eq(0) // cloud shadow
                .and(quality.bitwiseAnd(32).eq(0) // cloud
                .and(quality.bitwiseAnd(4).eq(0))); // water
  return lsImg.updateMask(clear)                                    
            .copyProperties(lsImg, ['system:time_start']);
};
```

#### Get snow-Covered Pixels

```{js snow mask}
// function: mask pixels without snow based on NDSI and NDFSI
var ndfsi_mask = function(image){
  var ndfsi_snow = image.select('ndfsi').gt(0.4);
  return image.updateMask(ndfsi_snow);
};
var ndsi_mask = function(image){
  var ndsi_snow = image.select('ndsi').gt(0.4);
  return image.updateMask(ndsi_snow);
};
```


### Map Functions Across Image Collection

```{js map and filter}
// map functions to create final Landsat collection
var ls_indices = ls4_8.map(calc_indices)
                      .map(qa_mask)
                      .map(ndfsi_mask)
                      .map(ndsi_mask);
```

## Create Annual Image Composites

### Functions to Create Annual Image Composites

#### Get Yearly Winter Image Composite

```{js}
// function: generates landsat composites for a given year's winter
var get_composites = function(year) {
  
  // format years
  var year_start = ee.Number(year).format().slice(0,4);
  
  var year2 = ee.Number(year).add(1)
  var year_end = ee.Number(year2).format().slice(0,4);
  
  var month_start = '-11-01';
  var month_end = '-05-01'
  
  var start_date = ee.String(year_start).cat(month_start)
  var end_date = ee.String(year_end).cat(month_end)

  // filter images by bounds, date range, bands; then take composite as median
  return ls_indices
    .filterBounds(fires_export_buffer1500)
    .filterDate(start_date,end_date)
    .filter(ee.Filter.calendarRange(12,4,"month"))	
    .select("blue", "green", "red", "nir", "swir1", "swir2", "ndvi", "ndwi", "nbr", "nbr2", "ndsi", "ndfsi", "evi")
    .median()
    .set("year_start",year_start)
    .set("year_end",year_end)
}
```

#### Get the Annual Imagery for Each Fire

```{js}
// function: clip each image from image collection by each feature in feature collection
var clip_collections = function(imagecol, featcol){
  // image collection loop
  var full_imagecol = imagecol.map(function(image){
    // feature collection loop
    var full_featcol = featcol.map(function(feat){
      // clip image and add feature property id
      return ee.Image(image).clip(ee.Feature(feat))
                            .set({'feat': ee.Feature(feat).id()})
                            .set("Fire_ID",feat.get("Fire_ID"));  
    });
    // convert the FeatureCollection to list and convert it to ImageCollection
    return ee.ImageCollection.fromImages(full_featcol.toList(featcol.size()));
  });
  // flatten, unnest lists
  return ee.ImageCollection(full_imagecol.flatten());
};
```

### Apply Functions to Each Image

```{js}
// list of start years
var yearlist = ee.List.sequence(1984,2020,1);

// map over the list of years to return landsat image composites for each
var wrap_img = yearlist.map(get_composites);

// clip landsat composites to each fire boundary
var landsat_col = ee.ImageCollection.fromImages(wrap_img)

// clip output
var output = clip_collections(landsat_col, fires_export_buffer1500)
```


## Prepare and Export Images

```{js}
// list fire IDs and get total number of fires
var fireID = ee.List(fires_export_buffer1500.aggregate_array('Fire_ID')).getInfo();
var nFires = fireID.length;
```

### Functions to Prepare Images

#### Get Year-Wavelength Band Names

```{js}
// rename bands to include imagery year
var name_bands = function(image) {
      var div = ee.String('_');
      var year = image.getString('year_start');
      return image.rename(image.bandNames().map(function(bandName){
        return ee.String(bandName).cat(div).cat(year);
      }));
    };
```

#### Get Cleaned Band Name Strings
```{js}
// remove prefix from toBands function
var clean_band_names = function(bandName){
        return ee.String(bandName).slice(24,50)
        }
```

### Export

```{js}
// loop through all fires, and create single image with bands from each landsat composite year
// export to drive
for (var j = 0; j < nFires; j++){
  
  var id   = fireID[j];
  var fireExport = output.filterMetadata('Fire_ID', 'equals', id)
  var firePolygon = ee.Feature(fires_export_buffer1500.filterMetadata('Fire_ID', 'equals', id).first()).geometry();

  var fireExport_bands = fireExport.map(name_bands)

  var merge = fireExport_bands.toBands()
  
  var exportImg= merge.rename(merge.bandNames().map(clean_band_names));
    
  Export.image.toDrive({
    image: exportImg,
    folder: "landsat_clipped_13bandyearly",
    description: id,
    crs: "EPSG:4326",
    maxPixels: 1e13,
    scale: 30,
    region: firePolygon
}); 
}
```


<!--chapter:end:06_imagery.Rmd-->

# Model Development

## Set Up

### Libraries

```{r libraries5, message=FALSE, warning=FALSE}
library(mapview)
library(sf)
library(terra)
library(tidyverse)
library(ggplot2)
library(car)
library(forcats)
library(randomForest)
library(raster)
```

### Import Fire Boundaries

```{r fire boundary import}
fires_export <- st_read("data/fire_boundaries/fires_export.shp")%>% 
  st_transform(., crs="EPSG: 4326")

crs <- crs(fires_export)
```

### Import Training Points

```{r import points}
# bring in training points
points <- st_read("data/points/points_export.shp") %>% 
  st_transform(crs=crs)%>% 
  drop_na()
```

## Prepare Imagery

### Prepare Data for Bands and Fire Names

#### Bands
```{r band names1, message=FALSE, warning=FALSE}
# list band names and years
bands <- c("blue", "green", "red", "nir", "swir1", "swir2", "ndvi", "ndwi", "nbr", "nbr2", "ndsi", "ndfsi", "evi")
years <- c(1984:2020)

# create list of all combinations of bands, in the appropriate order
bandnames <- list(bands,years) %>%
  cross() %>%
  map(lift(paste0))

bandlist <- do.call(rbind,bandnames)
```

#### Fire Names

```{r fire names2, message=FALSE, warning=FALSE}
# get list of fire names
fire_names_all <- unique(fires_export$Fire_ID)
fire_names_points <- unique(points$Fire_ID,na.rm=TRUE)
```

### Merge Large Rasters

```{r merge function, message=FALSE, warning=FALSE,results='hide'}
# function to merge rasters, if there are multiple in the folder
export_rasters <- function(fire_name){
  print(paste0("Starting Fire ",fire_name))
  
  # get list of this fire's tif files
  rast_list <- list.files(path = "data/landsat/landsat_annual", pattern=fire_name, all.files=TRUE, full.names=TRUE)
  
  # larger rasters were exported from GEE as multiple files, need to be combined before importing
  if (length(rast_list)>1) { 
    print(paste0(length(rast_list)," rasters, merging..."))
    rast_all <- lapply(rast_list, rast)
    rast_collection <- do.call(merge,rast_all)
    writeRaster(rast_collection, str_c("data/landsat/landsat_annual/",fire_name,".tif"), overwrite=FALSE,gdal="COMPRESS=NONE")
    } else { 
    print("Only one raster, can extract directly")
    }
}
```

```{r message=FALSE, warning=FALSE,eval=FALSE}
map(fire_names_all,export_rasters)
```

## Extract Landsat Data 

```{r extract function, message=FALSE,warning=FALSE}
extract_landsat <- function(fire_name){
  
  print(paste0("Starting Fire ",fire_name))
  
  # get this fire's tif files
  rast_list <- list.files(path = "data/landsat/landsat_training", pattern=str_c(fire_name,".tif"), all.files=TRUE, full.names=TRUE)
  rast_fire <- rast(rast_list)  

  # name the bands
  names(rast_fire) <- bands
  
  # verify crs
  crs(rast_fire) <- "EPSG: 4326"
  
  # filter the points for this fire
  fire_points <- points %>% 
    filter(Fire_ID==fire_name) %>% 
    st_transform(crs=crs(rast_fire))
  
  # get the mean landsat values for each patch in this fire
  extracted_points <- st_as_sf(terra::extract(rast_fire, fire_points,bind = TRUE))
  
  # export
  return(extracted_points)
}
```

```{r extract, message=FALSE, warning=FALSE,results = 'hide'}
# extract landsat values to each training point
extracted_df <- map(fire_names_points, extract_landsat)
```

### Prepare Dataset

```{r clean dataset}
# compile dataset and clean dataset
training_dataset <- do.call(rbind,extracted_df) %>% 
  mutate(absence = as.factor(case_when(class == "absence" ~ "absence",
                                       TRUE ~ "presence")),
         binom = as.factor(case_when(class == "absence" ~ 0,
                                       TRUE ~ 1)),
         class = case_when(class == "presence20to40" ~ "20-60%",
                           class == "presence40to60" ~ "20-60%",
                           class == "presence10to20" ~ "10-20%",
                           class == "presence1to10" ~ "1-10%",
                           class == "presencetrace" ~ "<1%",
                           class == "presence60plus" ~ ">60%",
                           TRUE ~ "absence"),
         class = fct_relevel(as.factor(class),c("absence","<1%","1-10%","10-20%","20-60%",">60%"))) %>% 
  st_drop_geometry() %>% 
  dplyr::select(-qd_vnt_,-qd_fr_d) %>% 
  drop_na(ndvi)
```

## Examine Data 

### Plot NDVI by Density Class

```{r ggplotting, message=FALSE, warning=FALSE}
ggplot(training_dataset,aes(class,ndvi)) +
  geom_boxplot() + 
  labs(title = "NDVI by Percent Conifer Cover Class: All Classes",x = "Visually Estimated Conifer Percent Cover",y = "NDVI")

ggplot(training_dataset %>% filter(class %in% c("absence","<1%")),aes(class,ndvi)) +
  geom_boxplot()+
  ylim(-.1,.1) + 
  labs(title = "NDVI by Percent Conifer Cover Class: Trace Conifer Class vs. Absence",x = "Visually Estimated Conifer Percent Cover",y = "NDVI")

ggplot(training_dataset,aes(absence,ndvi)) +
  geom_boxplot() + 
  labs(title = "NDVI by Percent Conifer Cover Class: Presence vs. Absence ",x = "Visually Estimated Conifer Percent Cover",y = "NDVI")
```

## Model

### Create Random Forest

```{r rf model}
rf_conifer <- randomForest(binom ~ red + green + blue + nir + swir1 + swir2 + ndsi + ndfsi + ndvi + evi + nbr + nbr2 + ndwi, data= training_dataset %>% drop_na())
```

### Evaluate

```{r rf model importance}
randomForest::importance(rf_conifer)
```

```{r rf model summary}
# summary
summary(rf_conifer)
```


```{r rf model export, eval = FALSE}
# export 
saveRDS(rf_conifer,"data/models/rf_conifer.rds")
```

<!--chapter:end:07_model.Rmd-->

# NDVI Trajectory

## Set Up

### Libraries 

```{r libraries6, message=FALSE, warning=FALSE}
library(ggplot2)
library(ggthemes)
library(tidyverse)
library(sf)
library(terra)
library(raster)
library(exactextractr)
library(forcats)
library(broom)
library(knitr)
library(sjPlot)
library(lwgeom)
library(lme4)
library(nlme)
library(segmented)
```

### Import Fires

```{r patch and fire import, message=FALSE, warning=FALSE, results='hide'}
# import high-severity patches
patches <- st_read("data/patches/highsev_patches.shp") %>% 
  st_transform(crs="EPSG: 4326") %>% 
  mutate(perim = st_cast(geometry,"MULTILINESTRING") %>% st_length(),
         perim_ratio = perim/ptch_r_)

# set crs
crs <- crs(patches)

# import fire boundaries
fires_export <- st_read("data/fire_boundaries/fires_export.shp")%>% 
  st_transform(., crs=crs)

# import mask of plantings and fires
mask <- st_read("data/patches/points_dataset_MASK.shp") %>% 
  st_transform(crs=crs) %>% 
  st_join(.,fires_export)

# final fire list
fire_names <- c("Fire_1_1988","Fire_2_1988","Fire_3_1988","Fire_4_1988","Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_54_1991")
```

### Prepare Data for Bands and Fire Names

#### Bands
```{r band names2, message=FALSE, warning=FALSE}
# list band names and years
bands <- c("blue", "green", "red", "nir", "swir1", "swir2", "ndvi", "ndwi", "nbr", "nbr2", "ndsi", "ndfsi", "evi")
years <- c(1984:2020)

# create list of all combinations of bands, in the appropriate order
bandnames <- list(bands,years) %>%
  cross() %>%
  map(lift(paste0))

bandlist <- do.call(rbind,bandnames)
```

#### Fire Names

```{r fire names1, message=FALSE, warning=FALSE}
# get list of fire names
fire_names <- unique(fires_export$Fire_ID)
```

## Connect Landsat and High-Severity Patches

### Extract Landsat Data for Each Patch

```{r extract function2, message=FALSE,warning=FALSE}
extract_landsat <- function(fire_name){
  
  print(paste0("Starting Fire ",fire_name))
  
  # get list of this fire's tif files
  rast_list <- list.files(path = "data/landsat/landsat_annual", pattern = str_c(fire_name,".tif"), all.files=TRUE, full.names=TRUE)
  rast_fire <- rast(rast_list)

  # name the bands
  names(rast_fire) <- bandlist
  
  # verify crs
  crs(rast_fire) <- "EPSG: 4326"
  
  # filter the patches for this fire
  fire_patches <- patches %>% 
    filter(Fire_ID==fire_name) %>% 
    st_transform(crs=crs(rast_fire))
    
  fire_mask <- mask %>% 
    filter(Fire_ID == fire_name)
  

  rast_fire <- mask(rast_fire,fire_mask,inverse=TRUE)
  
  # get the mean landsat values for each patch in this fire
  extracted_data <- left_join(fire_patches, exact_extract(rast_fire,fire_patches, append_cols = TRUE, max_cells_in_memory = 3e+08, fun = "mean")) %>% 
    st_drop_geometry()

    # export
  return(extracted_data)
}
```

```{r extract landsat, message=FALSE, results='hide', cache=TRUE}
# map extraction function across all fires
extracted_fires <- map(fire_names,extract_landsat)

# combine landsat dataset
landsat_dataset <- do.call(rbind, extracted_fires) %>% 
  st_drop_geometry()
```

## Prepare Dataset 

### Clean Data

```{r clean dataset2}
# clean dataset, label, select only ndvi, calculate pre-fire ndvi & differenced ndvi
ndvi_dataset_full <- landsat_dataset %>% 
  mutate(Patch_ID = str_c(Fire_ID,"-",1:n()),
         prefire_yr = as.integer(year-1),
         patch_area_class = fct_relevel(as.factor(case_when(ptch_r_ >= 1000 ~ ">1000 acres",
                                                ptch_r_ < 1000 & ptch_r_ >= 500 ~ "500-1000 acres",
                                                ptch_r_ < 500 & ptch_r_ >= 100 ~ "100-500 acres",
                                                ptch_r_ < 100 & ptch_r_ >= 50 ~ "50-100 acres",
                                                ptch_r_ < 50 & ptch_r_ >= 10 ~ "10-50 acres",
                                                TRUE ~ "<10 acres")),
                                        c("<10 acres","10-50 acres","50-100 acres","100-500 acres","500-1000 acres",">1000 acres"))) %>% 
  dplyr::select(Evnt_ID, Incd_Nm, Fire_ID, Patch_ID, prefire_yr, year, 
                ecoregn, ptch_fr, ptch_r_, patch_area_class, contains("ndvi")) %>%
  pivot_longer(.,contains("ndvi"),names_to = "landsat_yr", values_to = "ndvi")%>% 
  mutate(landsat_yr = as.integer(landsat_yr %>%  stringr::str_remove("mean.ndvi")),
         years_postfire = landsat_yr - year) %>% 
  mutate(prefire_ndvi = case_when(years_postfire == -1 ~ ndvi)) %>% 
  group_by(Patch_ID) %>% 
  mutate(prefire_ndvi = mean(prefire_ndvi, na.rm=TRUE)) %>%
  ungroup() %>% 
  mutate(delta_ndvi = ndvi - prefire_ndvi)%>%  
  filter(ptch_fr %in% c("Lodegepole Pine","Douglas-Fir","Fir-Spruce"),
         Fire_ID %in% fire_names) %>% 
  mutate(ptch_fr = case_when(ptch_fr == "Lodegepole Pine" ~ "Lodgepole Pine",
                                      TRUE ~ ptch_fr))%>% 
  drop_na() 
```

## Modeling

### Forest Type Groups

#### Model 
```{r}
ndvi_grouped_type <- ndvi_dataset_full %>% 
  group_by(ptch_fr,years_postfire) %>% 
  summarize(ndvi=mean(ndvi,na.rm=TRUE),
            delta_ndvi = mean(delta_ndvi,na.rm=TRUE)) %>% 
  drop_na()

# model NDVI difference for each forest type
data_df <- ndvi_grouped_type%>% filter(ptch_fr == "Douglas-Fir") %>%  filter(years_postfire>=0)
data_lp <- ndvi_grouped_type%>% filter(ptch_fr == "Lodgepole Pine") %>%  filter(years_postfire>=0)
data_fs<- ndvi_grouped_type%>% filter(ptch_fr == "Fir-Spruce") %>%  filter(years_postfire>=0)

lm_ndvi_df <- lm(delta_ndvi ~ years_postfire, data = data_df%>%  filter(years_postfire>=0))
seg_ndvi_df <- segmented(lm_ndvi_df,seg.Z = ~ years_postfire,npsi =1)
data_df$fit <- seg_ndvi_df$fitted.values

lm_ndvi_lp <-  lm(delta_ndvi ~ years_postfire,  data = data_lp)
seg_ndvi_lp <- segmented(lm_ndvi_lp,seg.Z = ~ years_postfire,npsi =1)
data_lp$fit <- seg_ndvi_lp$fitted.values

lm_ndvi_fs <-  lm(delta_ndvi ~ years_postfire, data = data_fs )
seg_ndvi_fs <- segmented(lm_ndvi_fs,seg.Z = ~ years_postfire,npsi =1)
data_fs$fit <- seg_ndvi_fs$fitted.values
```

#### Estimates

```{r}
model_ndvi_df <- as.data.frame(do.call(rbind,map(list(seg_ndvi_df,seg_ndvi_lp,seg_ndvi_fs), coef))) %>%
  rename(intercept = "(Intercept)",
         slope1 = U1.years_postfire,
         slope2 = years_postfire) %>% 
  mutate(bp = c(11.45,14.643,19.378),
         years_recovery = -intercept/slope1 + bp)

rownames(model_ndvi_df) <- c("Douglas-Fir","Lodgepole Pine","Fir-Spruce")

```
#### Plot

```{r}
ggplot()+
  geom_point(data = ndvi_grouped_type, aes(x= years_postfire,y = delta_ndvi,color = ptch_fr)) +
  geom_line(data= data_df %>% filter(years_postfire > 0 & years_postfire<11.45),aes(x=years_postfire,y=fit),color = "#F8766D") +
  geom_line(data= data_df%>% filter(years_postfire >= 11.45),aes(x=years_postfire,y=fit),color = "#F8766D") +
  geom_line(data= data_lp %>% filter(years_postfire > 0 & years_postfire<14.643),aes(x=years_postfire,y=fit),color = "#619CFF") +
  geom_line(data= data_lp%>% filter(years_postfire >= 14.643),aes(x=years_postfire,y=fit),color = "#619CFF") +
  geom_line(data= data_fs %>% filter(years_postfire > 0 & years_postfire<19.378),aes(x=years_postfire,y=fit),color = "#00BA38") +
  geom_line(data= data_fs%>% filter(years_postfire >= 19.378),aes(x=years_postfire,y=fit),color = "#00BA38") +
  labs(x="Years Post-Fire",y="dNDVI",color = "Forest Type",title= "NDVI Change Overtime 30 Years Post-Fire", subtitle = "Comparing Forest Types") +
  geom_hline(yintercept= 0,linetype="dashed",color="black",size=1)+
  annotate("text", x=12, y=0.015, label="Pre-Fire Snow-Cover NDVI")+
  theme_classic()
```
### Ecoregions

#### Model 
```{r}
ndvi_grouped_ecoregion <- ndvi_dataset_full %>% 
  group_by(ecoregn,years_postfire) %>% 
  summarize(ndvi=mean(ndvi,na.rm=TRUE),
            delta_ndvi = mean(delta_ndvi,na.rm=TRUE)) %>% 
  drop_na()

# model NDVI difference for each forest type
data_mr <- ndvi_grouped_ecoregion%>% filter(ecoregn == "Middle Rockies") %>%  filter(years_postfire>=0)
data_nr <- ndvi_grouped_ecoregion%>% filter(ecoregn == "Northern Rockies") %>%  filter(years_postfire>=0)
data_cr <- ndvi_grouped_ecoregion%>% filter(ecoregn == "Canadian Rockies") %>%  filter(years_postfire>=0)
data_ib<- ndvi_grouped_ecoregion%>% filter(ecoregn == "Idaho Batholith") %>%  filter(years_postfire>=0)

lm_ndvi_mr <- lm(delta_ndvi ~ years_postfire, data = data_mr)
seg_ndvi_mr <- segmented(lm_ndvi_mr,seg.Z = ~ years_postfire,npsi =1)
data_mr$fit <- seg_ndvi_mr$fitted.values

lm_ndvi_nr <- lm(delta_ndvi ~ years_postfire, data = data_nr)
seg_ndvi_nr <- segmented(lm_ndvi_nr,seg.Z = ~ years_postfire,npsi =1)
data_nr$fit <- seg_ndvi_nr$fitted.values

lm_ndvi_cr <-  lm(delta_ndvi ~ years_postfire,  data = data_cr)
seg_ndvi_cr <- segmented(lm_ndvi_cr,seg.Z = ~ years_postfire,npsi =1)
data_cr$fit <- seg_ndvi_cr$fitted.values

lm_ndvi_ib <-  lm(delta_ndvi ~ years_postfire, data = data_ib )
seg_ndvi_ib <- segmented(lm_ndvi_ib,seg.Z = ~ years_postfire,npsi =1)
data_ib$fit <- seg_ndvi_ib$fitted.values
```

#### Estimates

```{r}
model_ndvi_df <- as.data.frame(do.call(rbind,map(list(seg_ndvi_mr,seg_ndvi_nr,seg_ndvi_cr,seg_ndvi_ib), coef))) %>%
  rename(intercept = "(Intercept)",
         slope1 = U1.years_postfire,
         slope2 = years_postfire) %>% 
  mutate(bp = c(17,8.964,8,13),
         years_recovery = -intercept/slope1 + bp)

rownames(model_ndvi_df) <- c("MR","NR","CR","IB")

```
#### Plot

```{r}
ggplot()+
  geom_point(data = ndvi_grouped_ecoregion, aes(x= years_postfire,y = delta_ndvi,color = ecoregn)) +
  geom_line(data= data_mr %>% filter(years_postfire > 0 & years_postfire<17),aes(x=years_postfire,y=fit),color = "#00BFC4") +
  geom_line(data= data_mr%>% filter(years_postfire >= 17),aes(x=years_postfire,y=fit),color = "#00BFC4") +
  geom_line(data= data_nr %>% filter(years_postfire > 0 & years_postfire<8.964),aes(x=years_postfire,y=fit),color = "#C77CFF") +
  geom_line(data= data_nr%>% filter(years_postfire >= 8.964),aes(x=years_postfire,y=fit),color = "#C77CFF") +
  geom_line(data= data_cr %>% filter(years_postfire > 0 & years_postfire<8),aes(x=years_postfire,y=fit),color = "#F8766D") +
  geom_line(data= data_cr%>% filter(years_postfire >= 8),aes(x=years_postfire,y=fit),color = "#F8766D") +
  geom_line(data= data_ib %>% filter(years_postfire > 0 & years_postfire<13),aes(x=years_postfire,y=fit),color = "#7CAE00") +
  geom_line(data= data_ib%>% filter(years_postfire >= 13),aes(x=years_postfire,y=fit),color = "#7CAE00") +
  labs(x="Years Post-Fire",y="dNDVI",color = "Ecoregion",title= "NDVI Change Overtime 30 Years Post-Fire", subtitle = "Comparing Ecoregions") +
  geom_hline(yintercept= 0,linetype="dashed",color="black",size=1)+
  annotate("text", x=12, y=0.015, label="Pre-Fire Snow-Cover NDVI")+
  theme_classic()
```

<!--chapter:end:08_NDVItrajectory_piecewise.Rmd-->

# Prediction

## Set Up

### Libraries

```{r libraries7, message=FALSE, warning=FALSE}
library(sf)
library(terra)
library(tidyverse)
library(ggplot2)
library(randomForest)
library(raster)
library(mapview)
```

### Import Fire Boundaries

```{r patches and fire import, message=FALSE, warning=FALSE, results='hide'}
# import high-severity patches
patches <- st_read("data/patches/highsev_patches.shp") %>% 
  st_transform(crs="EPSG: 4326")

# set crs
crs <- crs(patches)

# import fire boundaries
fires_export <- st_read("data/fire_boundaries/fires_export.shp")%>% 
  st_transform(., crs=crs)

# import mask of plantings and fires
mask <- st_read("data/patches/points_dataset_MASK.shp") %>% 
  st_transform(crs=crs) %>% 
  st_join(.,fires_export)
```

### Import Models

```{r}
rf_conifer <- readRDS("data/models/rf_conifer.rds")
# lm_conifer <- readRDS("data/models/lm_conifer.rds")
```


### Prepare Raster Naming

#### Bands
```{r band names3, message=FALSE, warning=FALSE}
# list band names and years
bands <- c("blue", "green", "red", "nir", "swir1", "swir2", "ndvi", "ndwi", "nbr", "nbr2", "ndsi", "ndfsi", "evi")
years <- c(1984:2020)

# create list of all combinations of bands, in the appropriate order
bandnames <- list(bands,years) %>%
  cross() %>%
  map(lift(paste0))

bandlist <- do.call(rbind,bandnames)
```

#### Fire Names

```{r fire names3, message=FALSE, warning=FALSE}
# get list of fire names
fire_names <- c("Fire_1_1988","Fire_2_1988","Fire_3_1988","Fire_4_1988","Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_54_1991")
```


## Prediction Rasters

### Predict Across Rasters

```{r prediction function, message=FALSE,warning=FALSE}
predict_landsat <- function(fire_name){
  print(paste0("Starting Fire ",fire_name))
  
  # import fire raster
  rast_list <- list.files(path = "data/landsat/landsat_annual", pattern=str_c(fire_name,".tif"), all.files=TRUE, full.names=TRUE)
  fire_raster <- rast(rast_list)  

  # name the bands, verify crs
  names(fire_raster) <- bandlist
  crs(fire_raster) <- "EPSG: 4326"
  
  # filter the patches for this fire
  fire_patches <- patches %>% 
    filter(Fire_ID==fire_name) %>% 
    st_transform(crs=crs(fire_raster))
  
  # filter mask for this fir
  fire_mask <- mask %>% 
    filter(Fire_ID == fire_name)
  
  # clip raster to outside of any masked areas
  fire_raster_mask <- mask(fire_raster,fire_mask,inverse=TRUE)
  
  # clip raster to patches
  raster_clip <- mask(fire_raster_mask,fire_patches)
  
  # set fire year
  fire_year_start <- mean(fire_patches$year)
  fire_year_end <- fire_year_start + 30
  
  # string of start years for 3-year image composites
  fire_year_seq <- sequence(10,from=fire_year_start, by = 3)
  
  pred_rasters <- list()
  for(i in 1:10){
    print(i)
    
    raster_yr1 <- raster_clip[as.character(fire_year_seq[i])]
    raster_yr2 <- raster_clip[as.character(fire_year_seq[i]+1)]
    raster_yr3 <- raster_clip[as.character(fire_year_seq[i]+2)]
    
    names(raster_yr1) <- list("blue", "green", "red", "nir", "swir1", "swir2", "ndvi", "ndwi", "nbr", "nbr2", "ndsi", "ndfsi", "evi")
    names(raster_yr2) <- list("blue", "green", "red", "nir", "swir1", "swir2", "ndvi", "ndwi", "nbr", "nbr2", "ndsi", "ndfsi", "evi")
    names(raster_yr3) <- list("blue", "green", "red", "nir", "swir1", "swir2", "ndvi", "ndwi", "nbr", "nbr2", "ndsi", "ndfsi", "evi")
    
    raster_set <- mean(raster_yr1,raster_yr2,raster_yr3,na.rm=TRUE)
    
    # rast_predicted_lm <- terra::predict(raster_set,lm_conifer, type="response", se.fit=TRUE, na.rm = TRUE,filename = str_c("data/prediction_rasters/",fire_name,"_lm_year",1+((i-1)*3),"to",i*3,".tif"))
    
    rast_predicted_rf <- terra::predict(raster_set,rf_conifer, type="response", se.fit=TRUE, na.rm = TRUE,filename = str_c("data/prediction_rasters/",fire_name,"_rf_year",1+((i-1)*3),"to",i*3,".tif"))
    
    # pred_rasters[str_c("lm_year",1+((i-1)*3),"to",i*3)] <- rast_predicted_lm
    pred_rasters[str_c("rf_year",1+((i-1)*3),"to",i*3)] <- rast_predicted_rf
  }
  
  # export
  return(pred_rasters)
}
```

```{r message=FALSE, warning=FALSE, results='hide', eval= FALSE}
# create dataset of prediction rasters for each model in 3 year increments
prediction_dataset <- map(fire_names,predict_landsat)

names(prediction_dataset) <- fire_names
```

<!--chapter:end:09_prediction.Rmd-->

# Model Validation

## Set Up

### Libraries

```{r libraries 8, message=FALSE, warning=FALSE}
library(sf)
library(terra)
library(raster)
library(tidyverse)
library(mapview)
```

### Import Patch and Fire Boundaries

```{r import necessary boundaries, message=FALSE, warning=FALSE}
# final fire list
fire_names <- c("Fire_1_1988","Fire_2_1988","Fire_3_1988","Fire_4_1988","Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_54_1991")

# import fire and patch boundaries
mtbs_fires <- st_read("data/fire_boundaries/mtbs_export.shp") %>% 
  filter(Fire_ID %in% fire_names)%>% 
  st_transform(crs="EPSG:4326")

highsev_patches <- st_read("data/patches/highsev_patches.shp") %>% 
  filter(Fire_ID %in% fire_names)%>% 
  st_transform(crs="EPSG:4326") 
```

### Import Prediction Rasters

```{r list rast, message=FALSE, warning=FALSE,eval=FALSE}
# get all rasters from final timepoint
rast_list <- list.files(path = "data/prediction_rasters", pattern="t9.tif", all.files=TRUE, full.names=TRUE)
```

## Calculate Predicted Proportions

### Calculate Areal Proportions for Each Fire
```{r get props, message=FALSE, warning=FALSE,eval=FALSE}
# create and map function to determine areal proportion of presence/absence for each fire
get_percentages <- function(rast_file){
  fire_rast <- rast(rast_file)
  perc <- freq(fire_rast) %>% 
    mutate(Fire_ID = sub( ".*rasters/", "", sub( "_rf_t.*", "", rast_file)),
           class = case_when(value == 1 ~ "absence",
                             value == 2 ~ "presence"),
           percent_area = round(count/sum(count),3),
           val_points = round(5+10*percent_area,0))
  return(perc)
}

valid_points_df <- do.call(rbind,map(rast_list,get_percentages))
```

### Create Validation Polygons for Each Fire

```{r create pres abs polys, message=FALSE, warning=FALSE,cache=TRUE}
# create and map function to create presence/absence polygons from prediction raster
get_polygons <- function(rast_file){
  fire_rast <- rast(rast_file)
  fire_poly <- as.polygons(fire_rast)
  fire_poly_sf <- st_as_sf(fire_poly) %>% 
  mutate(Fire_ID = sub( ".*rasters/", "", sub( "_rf_t.*", "", rast_file)))
  return(fire_poly_sf)
}

class_polys <- do.call(rbind,map(rast_list,get_polygons))
```

## Prepare Validation Zones

### Assign Required Points to Each Polygon

```{r inform sample polys, message=FALSE, warning=FALSE,eval=FALSE}
sample_polys <- left_join(class_polys,valid_points_df,by=c("Fire_ID","class")) %>% 
  st_transform(., crs="EPSG:4326")
```

### Export

```{r expost sample polygons,message=FALSE, warning=FALSE,eval = FALSE}
# st_write(sample_polys,"data/validation/validation_polygons.shp")
```


<!--chapter:end:10_validation.Rmd-->


# Patch Fate

## Set Up

### Libraries
```{r libraries10, message=FALSE, warning=FALSE}
library(tidyverse)
library(terra)
library(sf)
library(ggsankey)
library(gridExtra)

sf_use_s2(FALSE)
```

### Import High-Severity Patches

```{r import patch3, message=FALSE, warning=FALSE}
# fire list
fire_list <- c("Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_54_1991","Fire_1_1988","Fire_2_1988","Fire_3_1988","Fire_4_1988")

# import high-severity patches
patches <- st_read("data/patches/highsev_patches.shp") %>% 
  mutate(Patch_ID = str_c(Fire_ID,"-",1:n())) %>% 
  st_transform(crs = "EPSG:4326")

# set crs
crs <- crs(patches)
```
## Calculate Patch Decomposition

### Function to Track Patch Changes
```{r message=FALSE, warning=FALSE}
get_patches <- function(fire_name){
  print(fire_name)
  
  # select last timepoint's raster
  rast_fire <- rast(str_c("data/prediction_rasters/",fire_name,"_rf_t9.tif"))

  # use the high severity patches as t0
  t0_patches <- patches %>% 
    filter(Fire_ID == fire_name) %>% 
    dplyr::select(Fire_ID, Patch_ID,ecoregn,ptch_fr) %>% 
    mutate(t0_area = as.numeric(st_area(.))/10000)
  
  # convert the t9 raster to polygons
  t9_patches <- as.polygons(rast_fire) %>% 
    st_as_sf() %>% 
    st_cast(to = "POLYGON") %>% 
    st_transform(crs = crs)
  
  # join the t9 polygons to the original t0 patches to track decomposition
  conversion_df <- st_join(t9_patches,t0_patches,left = TRUE,largest = TRUE) %>% 
    st_intersection(.,st_union(t0_patches))%>% 
    mutate(t9_area = as.numeric(st_area(.))/10000) %>% 
    st_drop_geometry()
    
    # export csv
  write_csv(conversion_df,str_c("data/patch_fate/",fire_name,".csv"))
}
```

### Apply Function to All Fires

```{r message=FALSE, warning=FALSE,eval = FALSE}
# get the decomposition df for each fire 
map(fire_list,get_patches)
```

### Create Dataset for Each Forest Type

```{r message=FALSE, warning=FALSE}
# import and join all decomposiition csvs
patch_data <- do.call(bind_rows,lapply(list.files(path = "data/patch_fate", pattern = "Fire", all.files=TRUE, full.names=TRUE),read_csv))%>% 
  mutate(t0_group = case_when(t0_area > 1000 ~ "1000ha+",
                                t0_area > 500 & t0_area <1000 ~ "500-1000ha",
                                t0_area > 100 & t0_area <5000 ~ "100-500ha",
                                t0_area > 50 & t0_area <100~ "50-100ha",
                                t0_area < 50 ~ "0-50ha"),
           t9_group = case_when(lyr1 == 1 & t9_area > 1000 ~ "1000ha+",
                                lyr1 == 1 & t9_area > 500 & t9_area <1000 ~ "500-1000ha",
                                lyr1 == 1 & t9_area > 100 & t9_area <5000 ~ "100-500ha",
                                lyr1 == 1 & t9_area > 50 & t9_area <100~ "50-100ha",
                                lyr1 == 1 & t9_area < 50 ~ "0-50ha",
                                lyr1 == 2 ~ "forested"))

# test  = patch_data %>% 
#   group_by(Patch_ID) %>% 
#   summarize(area = mean(t0_area))
# sum(test$area)
# sum(patch_data$t9_area)

# filter data to each forest type, and prepare data for alluvial polot
patches_df <- patch_data %>% 
  filter(ptch_fr == "Douglas-Fir") %>% 
  make_long(t0_group,t9_group,value = t9_area)
patches_df$node <- factor(patches_df$node,levels = c("forested","0-50ha","50-100ha","100-500ha","500-1000ha","1000ha+"))
patches_df$next_node <- factor(patches_df$next_node,levels = c("forested","0-50ha","50-100ha","100-500ha","500-1000ha","1000ha+"))
patches_df$value <- as.numeric(patches_df$value)

patches_lp <- patch_data %>% 
  filter(ptch_fr == "Lodegepole Pine")%>% 
  make_long(t0_group,t9_group,value = t9_area)
patches_lp$node <- factor(patches_lp$node,levels = c("forested","0-50ha","50-100ha","100-500ha","500-1000ha","1000ha+"))
patches_lp$next_node <- factor(patches_lp$next_node,levels = c("forested","0-50ha","50-100ha","100-500ha","500-1000ha","1000ha+"))
patches_lp$value <- as.numeric(patches_lp$value)

patches_fs <- patch_data %>% 
  filter(ptch_fr == "Fir-Spruce")%>% 
  make_long(t0_group,t9_group,value = t9_area)
patches_fs$node <- factor(patches_fs$node,levels = c("forested","0-50ha","50-100ha","100-500ha","500-1000ha","1000ha+"))
patches_fs$next_node <- factor(patches_fs$next_node,levels = c("forested","0-50ha","50-100ha","100-500ha","500-1000ha","1000ha+"))
patches_fs$value <- as.numeric(patches_fs$value)
```

## Plot

### Develop Plotting

```{r}
# prepare alluvial plots for each forest type

# order by the node category
patches_lp <- patches_lp[order(patches_lp$next_node),]

# used to block the forested patch flows from color set
alphas2 <- c(rep(0,2800),rep(0.8,8600))

# used to block unforested patch flows from the null color set
colors <- c(rep("gray",2800),rep("#fc8d59",8600))
alphas <- c(rep(.4,2800),rep(0,8600))
               
plot_lp<- ggplot(patches_lp, aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node,value = value)) +
  geom_alluvial(flow.alpha = alphas2,width =.2)+# plots colored flows for the unforested patches
  geom_alluvial(flow.alpha = alphas,flow.fill=colors,width =.2) +# plots null flows for the forested patches
  geom_alluvial_text(size = 3.2, color = "black") +# adds node label
  scale_fill_manual(values = c('#fef0d9','#fc8d59','#b30000','#fdcc8a','#e34a33',"gray")) + # adds base node colors
  theme_alluvial(base_size = 12) +# sets font/plot size
  labs(x = NULL, y= NULL,title = "Lodgepole Pine") +# labels
  theme(legend.position = "none")+# remove legend title
  theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5),axis.text.x = element_text(vjust = 6)) + # centers the plot title, adjust x axis labels
  scale_x_discrete(labels = c('0 Years\nPost-Fire','30 Years\nPost-Fire'),expand = c(0, 0))  +# relabels the x axis names
  theme(panel.grid = element_blank(),panel.border = element_blank()) # remove excess white space

patches_df <- patches_df[order(patches_df$next_node),]

alphas2 <- c(rep(0,2800),rep(0.8,6200))
colors <- c(rep("gray",2800),rep("#fc8d59",6200))
alphas <- c(rep(.4,2800),rep(0,6200))
               
plot_df<- ggplot(patches_df, aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node,value = value)) +
  geom_alluvial(flow.alpha = alphas2,width =.2)+
  geom_alluvial(flow.alpha = alphas,flow.fill=colors,width =.2) +
  geom_alluvial_text(size = 3.2, color = "black") +
  scale_fill_manual(values = c('#fef0d9','#fc8d59','#b30000','#fdcc8a','#e34a33',"gray")) + 
  theme_alluvial(base_size = 12) +
  labs(x = NULL, y= NULL,title = "Douglas-Fir") +
  theme(legend.position = "none")+
  theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5),axis.text.x = element_text(vjust = 6)) + 
  scale_x_discrete(labels = c('0 Years\nPost-Fire','30 Years\nPost-Fire'), expand = c(0, 0))  +
   theme(panel.grid = element_blank(),
        panel.border = element_blank())

patches_fs <- patches_fs[order(patches_fs$next_node),]

colors <- c(rep("gray",2800),rep("#fc8d59",10400))
alphas <- c(rep(.4,2800),rep(0,10400))
alphas2 <- c(rep(0,2800),rep(0.8,10400))
               
plot_fs <-ggplot(patches_fs, aes(x = x, next_x = next_x, node = node, next_node = next_node, fill = factor(node), label = node,value = value)) +
  geom_alluvial(flow.alpha = alphas2,width =.2)+
  geom_alluvial(flow.alpha = alphas,flow.fill=colors,width =.2) +
  geom_alluvial_text(size = 3.2, color = "black") +
  scale_fill_manual(values = c('#fef0d9','#fc8d59','#b30000','#fdcc8a','#e34a33',"gray")) + 
  theme_alluvial(base_size = 12) +
  labs(x = NULL, y= NULL,title = "Fir-Spruce") +
  theme(legend.position = "none") +
  theme(plot.title = element_text(hjust = 0.5),plot.subtitle = element_text(hjust = 0.5), axis.text.x = element_text(vjust = 6)) +
  scale_x_discrete(labels = c('0 Years\nPost-Fire','30 Years\nPost-Fire'), expand = c(0, 0))  +
  theme(panel.grid = element_blank(),
        panel.border = element_blank())
```

### All Three Forest Types

```{r, fig.width = 14,fig.height = 6}
# plot the three plots together
grid.arrange(plot_df,plot_lp,plot_fs,ncol=3,top = "Patch Decomposition 30-Years Post-Fire", left = "Total Patch Area (ha)")
```

### Forest Types Individually

```{r, fig.align='center',fig.width=6,fig.height=7}
# plot individually
plot_df + labs(y= "Total Patch Area (ha)",title = "Decomposition of Unforested Patches",subtitle = "Douglas-Fir")
plot_lp + labs(y= "Total Patch Area (ha)",title = "Decomposition of Unforested Patches",subtitle = "Lodgepole Pine")
plot_fs + labs(y= "Total Patch Area (ha)",title = "Decomposition of Unforested Patches",subtitle = "Fir-Spruce")
```

<!--chapter:end:11_patchfate.Rmd-->


# Patch Fate

## Set Up

### Libraries
```{r libraries11, message=FALSE, warning=FALSE}
library(tidyverse)
library(terra)
library(sf)
library(ggsankey)
library(gridExtra)

sf_use_s2(FALSE)
```

### Import High-Severity Patches

```{r import patch4, message=FALSE, warning=FALSE}
# fire list
fire_list <- c("Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_54_1991","Fire_1_1988","Fire_2_1988","Fire_3_1988","Fire_4_1988")

# import high-severity patches
patches <- st_read("data/patches/highsev_patches.shp") %>% 
  mutate(Patch_ID = str_c(Fire_ID,"-",1:n())) %>% 
  st_transform(crs = "EPSG:4326")

# set crs
crs <- crs(patches)
```
### Create Dataset for Each Forest Type

```{r message=FALSE, warning=FALSE}
# import and join all decomposiition csvs
patch_data <- do.call(bind_rows,lapply(list.files(path = "data/patch_fate", pattern = "Fire", all.files=TRUE, full.names=TRUE),read_csv))%>% 
  mutate(t0_group = case_when(t0_area > 1000 ~ "1000ha+",
                                t0_area > 500 & t0_area <1000 ~ "500-1000ha",
                                t0_area > 100 & t0_area <5000 ~ "100-500ha",
                                t0_area > 50 & t0_area <100~ "50-100ha",
                                t0_area < 50 ~ "0-50ha"),
           t9_group = case_when(lyr1 == 1 & t9_area > 1000 ~ "1000ha+",
                                lyr1 == 1 & t9_area > 500 & t9_area <1000 ~ "500-1000ha",
                                lyr1 == 1 & t9_area > 100 & t9_area <5000 ~ "100-500ha",
                                lyr1 == 1 & t9_area > 50 & t9_area <100~ "50-100ha",
                                lyr1 == 1 & t9_area < 50 ~ "0-50ha",
                                lyr1 == 2 ~ "forested"))
```
## Plot

## Identify Patches with Remaining Unforested Areas

```{r}
patch_list <- patch_data %>% 
  group_by(Patch_ID,lyr1) %>% 
  summarize(t0_area = mean(t0_area),
            t9_area = round(sum(t9_area),5)) %>% 
  pivot_wider(values_from = t9_area,names_from=lyr1) %>% 
  rename(t9_area_unforested = 4,
         t9_area_forested = 3) %>% 
  replace(is.na(.), 0) %>% 
  mutate(perc_forested = t9_area_forested/(t9_area_forested+t9_area_unforested),
         recovered = case_when(perc_forested <= .9 ~ "no",
                               TRUE ~ "yes"))

# write_csv(patch_list,"data/patches/patch_recovery_status.csv") 
```

```{r}
patch_metrics <- patches %>% 
  dplyr::select(Fire_ID,Patch_ID,ptch_fr,ecoregn) %>% 
  st_transform(3488) %>% 
  mutate(patch_area = round(as.numeric(st_area(.))/10000,4),
         perim_m = as.numeric(round(st_length(st_cast(geometry,to = "MULTILINESTRING")),4)),
         edge_perim_rat = patch_area/perim_m) %>% 
  st_buffer(-100) %>% 
  mutate(core_area = round(as.numeric(st_area(.))/10000,4),
         perc_core = round(core_area / patch_area,5))%>% 
  st_drop_geometry()
```


```{r}
patch_recovery <- left_join(patch_list,patch_metrics,by = "Patch_ID") %>% 
  mutate(t0_group = case_when(t0_area > 1000 ~ "1000ha+",
                                t0_area > 500 & t0_area <1000 ~ "500-1000ha",
                                t0_area > 100 & t0_area <5000 ~ "100-500ha",
                                t0_area > 50 & t0_area <100~ "50-100ha",
                                t0_area < 50 ~ "0-50ha"))

patch_recovery <- patch_recovery %>% drop_na()%>% 
  filter(ptch_fr %in% c("Douglas-Fir","Lodegepole Pine","Fir-Spruce"))
# 
# lm_recovery <- lm(perc_forested ~ patch_area + perc_core + edge_perim_rat  , data = patch_recovery)
# 
# + ptch_fr + ecoregn
# summary(lm_recovery)
# 
# anova(lm_recovery)
# 
# ggplot(patch_recovery ,aes(edge_perim_rat,perc_forested,color=ptch_fr)) +
#   geom_point() +
#   geom_smooth()
```


<!--chapter:end:12_patchmetrics.Rmd-->

# Landscape Expansion

## Set Up

### Import Libraries

```{r libraries9, message=FALSE, warning=FALSE}
library(sf)
library(terra)
library(mapview)
library(raster)
library(tidyverse)
library(ggplot2) 
library(exactextractr)
```

### Import Patch Polygons

```{r import patch5, message=FALSE, warning=FALSE}
# fire list
fire_list <- c("Fire_54_1991","Fire_4_1988","Fire_7_1988","Fire_9_1988","Fire_10_1988","Fire_11_1988","Fire_12_1988","Fire_13_1988","Fire_14_1988","Fire_15_1988","Fire_16_1988","Fire_18_1988","Fire_19_1988","Fire_20_1988","Fire_22_1988","Fire_23_1988","Fire_25_1988","Fire_26_1988","Fire_28_1988","Fire_29_1988","Fire_31_1988","Fire_32_1989","Fire_33_1989","Fire_35_1989","Fire_38_1989","Fire_41_1989","Fire_42_1989","Fire_48_1990","Fire_49_1991","Fire_50_1991","Fire_51_1991","Fire_1_1988","Fire_2_1988","Fire_3_1988")
fire_list_large <- c("Fire_1_1988","Fire_2_1988","Fire_3_1988")
fire_list_small <- fire_list[! fire_list %in% fire_list_large]

# import high-severity patches
patches <- st_read("data/patches/highsev_patches.shp") %>% 
  mutate(Patch_ID = str_c(Fire_ID,"-",1:n())) %>% 
  st_transform(crs = "EPSG:4326")

# set crs 
crs <- crs(patches)
```

## Calculate Landscape Patterns

### Calculate LEI for Each Patch's Growth

```{r message=TRUE, warning=FALSE}
get_simplelei <- function(fire_name){
  # print patch ID 
  print(fire_name)
  
  # filter to this specific patch
  patches_fire <- patches %>% 
    dplyr::filter(Fire_ID == fire_name)

  # import and name rasters for that fire
  rast_list <- list.files(path = "data/prediction_rasters", pattern = str_c(fire_name,"_rf"), all.files=TRUE, full.names=TRUE)
  rast_names <- str_sub(rast_list,start = -6, end = -5)  
  rast_fire <- rast(rast_list)
  names(rast_fire) <- rast_names
    
  # exclude t0 (no previous timestep to compare to)
  loop_names <- rast_names[2:10]
  
  # choose function to be performed based on fire size
  lei_fullset <- if(fire_name %in% fire_list_small){
    lapply(loop_names,
           get_timesteps_small,
           rast_fire=rast_fire,patches_fire=patches_fire)
  } else{
    lapply(loop_names,
           get_timesteps_large,
           rast_fire=rast_fire,patches_fire=patches_fire)    
  }
  
  lei_df <- do.call(rbind,lei_fullset)
  
  return(lei_df)
}
```

### Function to Handle LEI in Small Patches

```{r}
# function to create LEI dataset for each fire's time steps
get_timesteps_small <- function(rast_name,rast_fire,patches_fire){
  print(rast_name)
  
  # select the timepoint and corresponding raster
  timepoint2 <- rast_name
  timepoint2_raster <- rast_fire[[timepoint2]]  %>% 
      as.factor() 
  
    # set up raster for the previous timepoint
  timepoint1 <- str_c("t",as.numeric(str_sub(timepoint2,2,2))-1)
  timepoint1_raster <- rast_fire[[timepoint1]]  %>% 
    as.factor() 

  # set area outside of patches to presence
  timepoint1_raster[is.na(timepoint1_raster)] <- 2
  
  # difference the two time points to identify areas of change
  timepoint_difference_raster <- timepoint2_raster - timepoint1_raster 

  # convert areas of new presence to polgyons
  timepoint_difference_polys <- as.polygons(timepoint_difference_raster) %>%
    st_as_sf() %>%
    st_cast("POLYGON") %>% 
    dplyr::filter(.[[1]] == 1) %>% 
      st_transform(crs=crs)%>%
      st_join(.,st_make_valid(patches_fire),largest=TRUE)
  
  # control for possibility of no new growth
  if(nrow(timepoint_difference_polys)==0){
    print("no polys")
    columns <- c("count",	"lei",	"Patch_ID",	"lei_category",	"timepoint")
    lei_df <- data.frame(matrix(nrow=0,ncol=length(columns)))
    colnames(lei_df) = columns
    return(lei_df)
  }else{
    val = 0
    lei_poly_df<- list()
    for(i in unique(timepoint_difference_polys$Patch_ID)){
      val = val + 1
      print(str_c(100*round(val/length(unique(timepoint_difference_polys$Patch_ID)),2),"%"))
      
      # get polygon of new growth area for each patch
      patch <- patches_fire %>% 
        dplyr::filter(Patch_ID ==i)
      newgrowth_patch <- timepoint_difference_polys %>% 
        dplyr::filter(Patch_ID == i) %>% 
        summarize(geometry= st_union(geometry))
      
      # buffer to desire lei considered difference, get ring by taking difference
      newgrowth_buffer <- st_as_sf(buffer(vect(newgrowth_patch),100)) %>%
        summarize(geometry = st_union(geometry))
      newgrowth_ring <- st_difference(newgrowth_buffer,newgrowth_patch)
      
      # mask previous timepoints raster to the ring polygon to see previous timestep conifer composition
      raster_ring <- mask(timepoint1_raster,newgrowth_ring)
      freq_df <- freq(raster_ring) %>% 
        mutate(lei = count/sum(count),
               Patch_ID = i)
      lei_poly_df[[i]] <- freq_df
    }
    
    # clean, combine
    lei_df <- do.call(rbind,lei_poly_df)  %>% 
        dplyr::filter(value ==2) %>% 
        dplyr::select(-layer,-value) %>% 
        mutate(lei_category = case_when(lei > 0.5 ~ "infill",
                                        lei < .01 ~ "leapfrog",
                                        TRUE ~ "expansion"),
               timepoint = rast_name)
    
    # export to csv
    write_csv(lei_df,str_c("data/lei_simple/",fire_name,"-",rast_name,".csv"))
  }
} 
```

### Function to Handle LEI in Large Patches

```{r}
# function to create LEI dataset for each fire's time steps
get_timesteps_large <- function(rast_name,rast_fire,patches_fire){
  print(rast_name)
  
  # select the timepoint and corresponding raster
  timepoint2 <- rast_name
  timepoint2_raster <- rast_fire[[timepoint2]]  %>% 
      as.factor() 
  
  # set up raster for the previous timepoint
  timepoint1 <- str_c("t",as.numeric(str_sub(timepoint2,2,2))-1)
  timepoint1_raster <- rast_fire[[timepoint1]]  %>% 
    as.factor() 

  # set area outside of patches to presence
  timepoint1_raster[is.na(timepoint1_raster)] <- 2
  
  # difference the two time points to identify areas of change
  timepoint_difference_raster <- timepoint2_raster - timepoint1_raster 

  # convert areas of new presence to polgyons
  timepoint_difference_polys <- as.polygons(timepoint_difference_raster) %>%
    st_as_sf() %>%
    st_cast("POLYGON") %>% 
    dplyr::filter(.[[1]] == 1) %>% 
    st_transform(crs=crs) %>% 
    st_join(.,patches_fire)

  lei_df<- data.frame()
  
  # control for possibility of no new growth
  if(nrow(timepoint_difference_polys)==0){
    print("no polys")
  } else {
    for(i in str_sort(unique(timepoint_difference_polys$Patch_ID))){
      print(i)
      
      # get polygon of new growth area for each patch
      patch <- patches_fire %>% 
        dplyr::filter(Patch_ID ==i)
      newgrowth_patch <- timepoint_difference_polys %>% 
        dplyr::filter(Patch_ID == i) %>% 
        summarize(geometry= st_union(geometry))
      
      # buffer to desire lei considered difference, get ring by taking difference
      newgrowth_buffer <- st_as_sf(buffer(vect(newgrowth_patch),100)) %>%
        summarize(geometry = st_union(geometry))
      newgrowth_ring <- st_difference(newgrowth_buffer,newgrowth_patch)
      
      # mask previous timepoints raster to the ring polygon to see previous timestep conifer composition
      raster_ring <- mask(timepoint1_raster,newgrowth_ring)
      freq_df <- freq(raster_ring) %>% 
        mutate(lei = count/sum(count),
               Patch_ID = i)%>% 
        dplyr::filter(value ==2) %>% 
        dplyr::select(-layer,-value)%>% 
        mutate(lei_category = case_when(lei > 0.5 ~ "infill",
                                        lei < .01 ~ "leapfrog",
                                        TRUE ~ "expansion"),
               timepoint = rast_name)
      
      lei_df <- rbind(lei_df,freq_df)
    }
    
    # export to csv
    write_csv(lei_df,str_c("data/lei_simple/",fire_name,"-",rast_name,".csv"))
  }
} 
```

### Apply Functions Across All Fires

```{r message=FALSE, warning=FALSE,eval = FALSE}
# map get_lei function to all fires and export simple patchwise lei data 
map(fire_list,get_simplelei)
```


## Analyze Patch-wise LEI

### Combine and Clean Data

```{r message=FALSE, warning=FALSE}
# import all patchwise lei csv files
lei_simple_df <-do.call(bind_rows,lapply(list.files(path = "data/lei_simple", pattern = "Fire", all.files=TRUE, full.names=TRUE),read_csv))

patches_df <- patches %>% 
  mutate(perim_m = as.numeric(round(st_length(st_cast(geometry,to = "MULTILINESTRING")),2)),
         edge_perim_rat = ptch_r_/perim_m,
         perim_rat_cat = case_when(edge_perim_rat > .004 ~ "high edge",
                                   TRUE ~ "low edge")) 

lei_simple_summary <- lei_simple_df %>% 
  left_join(patches_df) %>% 
  filter(ptch_fr %in% c("Douglas-Fir","Fir-Spruce","Lodegepole Pine")) %>% 
  mutate(time_yr = case_when(timepoint == "t0" ~ 2,
                              timepoint == "t1" ~ 5,
                              timepoint == "t2" ~ 8,
                              timepoint == "t3" ~ 11,
                              timepoint == "t4" ~ 14,
                              timepoint == "t5" ~ 17,
                              timepoint == "t6" ~ 20,
                              timepoint == "t7" ~ 23,
                              timepoint == "t8" ~ 26,
                              timepoint == "t9" ~ 29))
```

### Plot

```{r message=FALSE, warning=FALSE}
ggplot(lei_simple_summary,aes(x=as.factor(time_yr),y=lei,fill=ptch_fr)) + 
  geom_boxplot(outlier.shape = NA) +
  labs(fill = "Forest Type",x = "Years Post-Fire",y="LEI",title = "LEI Over Time for Each Forest Type")+
  theme_classic()
```


<!--chapter:end:13_lei_simplepatchwise.Rmd-->

